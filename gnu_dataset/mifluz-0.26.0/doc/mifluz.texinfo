\input texinfo                @c -*- Texinfo -*-
@c %**start of header
@setfilename mifluz.info
@settitle @code{Mifluz}
@setchapternewpage odd
@c %**end of header

@set RCSID $Id: mifluz.texinfo,v 1.41 2002/04/29 19:14:14 loic Exp $
@include version.texi

@c Combine the variable and function indices:
@syncodeindex vr fn
@c Combine the program and concept indices:
@syncodeindex pg cp

@dircategory Information retrieval
@direntry
* Mifluz: (mifluz).		The GNU C++ full text indexing library.
@end direntry

@titlepage
@title Mifluz
@subtitle A full text indexing library
@subtitle @code{Mifluz} Version @value{VERSION}
@subtitle @value{UPDATED}
@author Lo@"{@dotless{i}}c Dachary, The ht://dig Group
@page
@vskip 0pt plus 1filll

 Permission is granted to make and distribute verbatim copies of
 this manual provided the copyright notice and this permission notice
 are preserved on all copies.

 Permission is granted to copy and distribute modified versions of this
 manual under the conditions for verbatim copying, provided that the entire
 resulting derived work is distributed under the terms of a permission
 notice identical to this one.

 Permission is granted to copy and distribute translations of this manual
 into another language, under the above conditions for modified versions,
 except that this permission notice may be stated in a translation approved
 by the Free Software Foundation.
@end titlepage
@page

@ifnottex
@node Top
@top Mifluz

@code{Mifluz} is a full text indexing library.

@end ifnottex

@menu
* Introduction::                
* Architecture::                
* Constraints::                 
* Document name scheme::        
* Data Storage Spec::           
* Cache tuning::                
* Key Specification::           
* Internals::                   
* Development::                 
* Reference::                   
* Concept Index::               
@end menu

@node Introduction
@chapter Introduction

First of all, @code{mifluz} is at beta stage. 

This program is part of the GNU project, released under the aegis of GNU.

The purpose of @code{mifluz} is to provide a C++ library to store a full
text inverted index. To put it briefly, it allows storage of occurrences of
words in such a way that they can later be searched. The basic idea of
an inverted index is to associate each unique word with a list of
documents in which they appear. This list can then be searched to locate
the documents containing a specific word.

Implementing a library that manages an inverted index is a very easy
task when there is a small number of words and documents. It becomes a
lot harder when dealing with a large number of words and
documents. @code{mifluz} has been designed with the further upper limits
in mind : 500 million documents, 100 giga words, 18 million document
updates per day. In the present state of @code{mifluz}, it is possible to
store 100 giga words using 600 giga bytes. The best average insertion
rate observed as of today 4000 key/sec on a 1 giga byte index.

@code{mifluz} has two main characteristics : it is very simple (one
might say stupidly simple :-) and uses 100% of the size of the indexed text for
the index. It is simple because it provides only a few basic
functions. It does not contain document parsers (HTML, PDF
etc...). It does not contain a full text query parser. It does not
provide result display functions or other user friendly stuff. It only
provides functions to store word occurrences and retrieve them. The fact
that it uses 100% of the size of the indexed text is rather
atypical. Most well known full text indexing systems only use 30%. The
advantage @code{mifluz} has over most full text indexing systems is that
it is fully dynamic (update, delete, insert), uses only a controlled
amount of memory while resolving a query, has higher upper limits and has a
simple storage scheme. This is achieved by consuming more disk space.

@node Architecture
@chapter Architecture

In the following figure you can see the place of @code{mifluz} in an hypothetical full
text indexing system. 

@image{drawarchi1,10cm,}

@table @samp

@item Query
Resolve full text queries. The optimization makes sure the least frequent 
terms are scanned first and that redundant query specifications are merged together.

@item Mifluz
Manage efficient storage of the inverted index permanent data.

@item Parser Switch
Transform raw documents into list of terms.

@item Indexer
Call the Parser Switch to get a list of terms and feed it to @code{mifluz}.

@end table

@node Constraints
@chapter Constraints

The following list shows all the constraints imposed by @code{mifluz}.
It can also be seen as a list of functions provided by @code{mifluz}
that is more general than the API specification.

@table @samp

@item Now Available

@itemize @bullet

@item 
In-place dynamic update of the index. 

@item
Use in memory cache to perform heavy index updates without stressing
the disk too much.

@item
The library can be linked in an C or C++ application, dynamically or
statically.

@item
The memory usage is completely controlled. The application can specify
the maximum total memory usage. The application can specify that the
memory cache will be shared among processes.

@item
The library is thread safe.

@end itemize

@item Future

@itemize @bullet

@item
Transaction logs for backup recovery.

@item
Index integrity check and repair function.

@item
Indexing up to 500 million documents and support up to 18 million document
updates per 24h. The average size of a document is 4 kilo bytes and contains
200 indexable words.

@end itemize

@item Constraints and Limitations

@itemize @bullet

@item
No atomic data is bigger than a size known in advance.
This postulate is essential for disk storage optimization. 
If an atomic data may have a size of 10Mb, it is impossible to guarantee 
that a query/indexing process controls the memory it's using.

An atomic datum is something that must be manipulated as whole, with
no possibility of splitting it into smaller parts. For instance a posting
(Word, document identifier and position) is an atomic datum:
to manipulate it in memory it has to reside completely in memory.
By contrast a postings list is not atomic. Manipulating a postings list
can be done without loading all the postings list in memory.

@item
The cost of an update is O(log m(N)) where m is the average number of
entries in a page and N the total number of pages. This figure has to
be considered when the pages are in memory or on disk.

@item
The inverted index data is sorted to fit the most typical search
pattern. The structure of the inverted index key can be defined at
run time to fit a usage pattern.

@item
No lock mechanism is provided beyond an individual word occurrence. It is
assumed that the library is linked in a central server that serializes
all the requests or in a program that provides its own lock mechanism.

@end itemize

@end table

@node Document name scheme
@chapter Document name scheme

In all of the literature dealing with full text indexing a collection of
documents is considered to be a flat set of documents containing
words. Each document has a unique name. The inverted index associates
terms found in the documents with a list of unique document names.

@image{drawdoc1,10cm,}

We found it more interesting to consider that the document names have a
hierarchical structure, just like path names in file systems. The main
difference is that each component of the document name (think path name
in file system) may contain terms.

As shown in the figure above we can consider that the first component of
the document name is the name of a collection, the second the logical
name of a set of documents within the collection, the third the name of
the document, the fourth the name of a part of the document.

@image{drawdoc2,10cm,}

This logical structure may be applied to URLs in the following way :
there is only one collection, it contains servers (document sets)
containing URLs (documents) containing tags such as TITLE (document
parts).

@image{drawdoc3,7cm,}

This logical structure may be also be applied to databases in the following
way : there is one collection for each database, it contains tables
(document set) containing fields (document) containing records (document
part).

What does this imply for full text indexing ? Instead of having only
one dictionary to map the document name to a numerical identifier (this
is needed to compress the postings for a term), we must have a
dictionary for each level of the hierarchy. 

Using the database example again:

@itemize @bullet

@item
A dictionary for database names

@item
A dictionary for table names

@item
A dictionary for field names

@item 
Since records are already identified by a number, no dictionary is needed.

@end itemize

When coding the document identifier in the postings for a term, we have
to code a list of numerical identifiers instead of a single numerical
identifier. Alternatively one could see the document identifier as an
aribtrary precision number sliced in parts.

The advantage of this document naming scheme are:

@itemize @bullet

@item
A @code{uniq} query operator can be trivially implemented. This is mostly
useful to answer a query such as : I want URLs matching the word foo
but I only want to see one URL for a given server (avoid the problem of
having the first 40 URLs for a request on the same server).

@item 
The posting lists are traditionally ordered according to the document
number.  This is a must to have an efficient query mechanism. With a
hierachical document name, each level of the hierarchy is
sorted. Therefore the postings are sorted in multiple ways: sorted by
collection first, then document set, then document part.

@item
Searching document paths is facilitated by the structure of the key.
For instance: I only want to
search TITLEs.

@end itemize

Of course, the suggested hierarchy semantic is not mandatory and may be
redefined according to sorting needs. For instance a relevance ranking
algorithm can lead to a relevance ranking number being inserted into the
hierarchy.

The space overhead implied by this name scheme is quite small for
databases and URL pools.  The big dictionary for URL pools maps URL to
identifiers. The dictionary for tags (TITLE etc..) is only 10-50 at
most. The dictionary for site names (www.domain.com) will be ~1/100 of
the dictionary for URLs, assuming you have 100 URLs for a given site. For
databases the situation is even better: the big dictionary would be the
dictionary mapping rowids to numerical identifiers. But since rowids are
already numerical we don't need this.  We only need the database name,
field name and table name dictionaries and they are small. Since we are
able to encode small numbers using only a few bits in postings, the
overhead of hierarchical names is acceptable.

@node Data Storage Spec
@chapter Data Storage Spec

Efficient management of the data storage space is an important issue of
the management of inverted indexes. The needs of an inverted index are
very similar to the needs of a regular file system. We need:

@itemize @bullet

@item
A cache associated with an LRU list to keep the
most frequently used entries in memory.

@item
To group postings into pages of fixed size to optimize I/O
on disk.

@item
A locking mechanism to prevent race conditions between threads or
multiple processes accessing the same data.

@item
A transaction system to ensure data integrity and atomicity of logical
operations.

@item
Transparent compression of pages to reduce I/O bottleneck for large
volumes of data and reduce disk usage as a bonus.

@item
To create indexes using up to 1 tera bytes.

@end itemize

All these functionalities are provided by file systems and kernel
services. Since we also wanted the @code{mifluz} library to be portable
we chose the Berkeley DB library that implements all the services
above. The transparent compression is not part of Berkeley DB and is
implemented as a patch to Berkeley DB (version 3.1.14).

Based on these low level services, Bekeley DB also implements a Btree
structure that @code{mifluz} used to store the postings. Each posting is
an entry in the Btree structure. Indexing 100 million words implies creating
100 million entries in the Btree. When transparent compression is
used and assuming we have 6 byte words and a document identifier using
7 * 8 bits, the average disk size used per entry is 6 bytes.

Unique word statistics are also stored in the inverted index. 
For each unique word, an entry is created in a dictionnary and associated
with a serial number (the word identifier and the total number of occurrences.

@node Cache tuning
@chapter Cache tuning

The cache memory used by @code{mifluz} has a tremendous impact on
performance.  It is set by the @strong{wordlist_cache_size} attribute
(see WordList(3) and mifluz(3)).  It holds pages from the inverted index
in memory (uncompressed if the file is compressed) to reduce disk
access. Pages migrate from disk to memory using a LRU.

Each page in the cache is really a node of the B-Tree used to store the inverted
index entries. The internal pages are intermediate nodes that @code{mifluz} must
traverse each time a key is searched. It is therefore very important to keep them in memory. 
Fortunately they only count for 1% of the total size of the index, at most. 
The size of the cache must at least include enough space for the internal pages.

The other factors that must be taken into account in sizing the cache are highly dependant
on the application. A typical case is insertion of many random words in the index.
In this case two factors are of special importance:

@table @samp

@item repartition of unique words
When filling an inverted index it is very likely that the dictionary of
unique words occuring in the index is limited. Let's say you have 1 000 000
unique words in a 100 000 000 occurrences index. Now assume that 90 000 000
occurrences are only using 20 000 unique words, that is 90% of the index is
filled with 2% of the complete vocabulary. If you are in this situation,
the indexing process will spend 90% of its time updating 20 000 pages.
If you can afford 20 000 * pagesize bytes of cache, you will have the
maximum insertion rate. 

The general rule is : estimate or calculate how many unique words fill
90% of your index. Multiply this number by the pagesize and increase your
cache by that amount. 
See @strong{wordlist_page_size} attribute in WordList(3) or mifluz(3). 

@item order of numbers following the key
The cache calculation above is fine as long as the words inserted are associated
with increasing numbers in the key. If the numbers following the word in the
key are random, the cache efficiency will be reduced. Where possible the application
should therefore make sure that when inserting two identical words, the first is
followed by a number that is lower than the second. In other words, insert

@example
foo 100
foo 103
@end example

rather than

@example
foo 103
foo 100
@end example

@end table

This hint must not be considered in isolation but with careful analysis of the
distribution of the key components (word and numbers). For instance it does
not matter much if a random key follows the word as long as the range
of values of the number is small.

The conclusion is that the cache size should be at least 1% of the total index
size (uncompressed) plus a number of bytes that depends on the usage pattern.

@node Key Specification
@chapter Key Specification

The key structure is what uniquely identifies each word that is inserted
in the inverted index. A key is made of a string (which is the word being
indexed), and a document identifier (which is really a list of numbers), as
discussed above.

The exact structure of the inverted index key must
be specified in the configuration parameter
@code{"wordlist_wordkey_description"}. See the WordKeyInfo(3) manual
page for more information on the format.

We will focus on three examples that illustrate common usage.

First example: a very simple inverted index would be to associate each word occurrence
to an URL (coded as a 32 bit number). The key description would be:

@example
Word 8/URL 32
@end example

Second example: if building a full text index of the content of a
database, you need to know in which field, table and record the word
appeared. This makes three numbers for the document id.

Only a few bits are needed to encode the field and table name (let's say
you have a maximum of 16 field names and 16 table names, 4 bits each is
enough). The record number uses 24 bits because we know we won't have
more than 16 M records.

The structure of the key would then be:

@example
Word 8/Table 4/Field 4/Record 32
@end example

When you have more than one field involved in a key you must chose the
order in which they appear. It is mandatory that the @strong{Word} is first. 
It is the part of the key that has highest precedence
when sorting. The fields that follow have lower and lower precedence.

Third example: we go back to the first example and imagine we have
a relevance ranking function that calculates a value for each word
occurrence. By inserting this relevance ranking value in the inverted
index key, all the occurrences will be sorted with the most relevant
first.

@example
Word 8/Rank 5/URL 32
@end example

@node Internals
@chapter Internals

@menu
* Compression::                 
@end menu

@node Compression
@section Compression

Compressing the index reduces disk space consumption
and speeds up the indexing by reducing I/O.

Compressing at the @code{mifluz} level would imply choosing complicated key
structures, slowing down and complexifying insert and delete
operations. We have chosen to do the compression within Berkeley DB in
the memory pool subsystem. Berkeley DB keeps fixed size pages in a
memory cache, when it is full it writes the least recently used pages to
disk. When a page is needed Berkeley DB looks for it in memory and
retrieves it from disk if its not in memory. The compression/uncompression
occurs when a page moves between the memory pool and the disk.

@image{cmprinfo-1,15cm,}

@menu
* Berkeley DB Compression::     
* Page compression in Mifluz::  
@end menu

@node Berkeley DB Compression
@subsection Compression inside Berekeley DB

Berkeley DB uses fixed size pages.  Suppose, for example that our compression
algorithm can compress by a factor of 8 in most cases, we use a disk
page size that's 1/8 of the memory page size.  However there are
exceptions. Some pages won't compress well and therefore won't fit on
one disk page. Extra pages are therefore allocated and are linked into a
chained list. Allocating extra pages implies that some pages may become
free as a result of a better compression. 

@image{dbcompress-1,15cm,}
@image{dbcompress-2,15cm,}
@image{dbcompress-3,15cm,}
@image{dbcompress-4,15cm,}

@node Page compression in Mifluz
@subsection Page compression in Mifluz

The @code{mifluz} classes WordDBCompress and WordBitCompress do the compression/decompression
work. From the list of keys stored in a page it extracts several lists
of numbers. Each list of numbers has common statistical properties that
allow good compression.

The  WordDBCompress_compress_c and WordDBCompress_uncompress_c
functions are C callbacks that  are called by the the page compression
code  in  BerkeleyDB. The  C  callbacks  then  call the  WordDBCompress
compress/uncompress  methods. The  WordDBCompress creates a WordBitCompress
object that acts as a buffer holding the compressed stream.

Compression algorithm.

Most DB pages contain redundant data because @code{mifluz} chose
to store one word occurrence per entry.
Because of this choice the pages have a very simple structure.

Here is a real world example of what a page can look like:
(key structure: word identifier + 4 numerical fields)

@example
756     1 4482    1  10b    
756     1 4482    1  142    
756     1 4484    1   40    
756     1 449f    1  11e    
756     1 4545    1   11    
756     1 45d3    1  545    
756     1 45e0    1  7e5    
756     1 45e2    1  830    
756     1 45e8    1  545    
756     1 45fe    1   ec    
756     1 4616    1  395    
756     1 461a    1  1eb    
756     1 4631    1   49    
756     1 4634    1   48    
.... etc ....
@end example

To compress we chose to only code differences between adjacent entries.
A flag is stored for each entry indicating which fields have changed.
When a field is different from the previous one, the compression stores
the difference which is likely to be small since the entries are sorted.

The basic idea is to build columns of numbers, one for each field, and
then compress them individually. One can see that the first and second
columns will compress very well since all the values are the same. The
third column will also compress well since the differences between the 
numbers are small, leading to a small set of numbers.

@node Development
@chapter Development

The development of @code{mifluz} is shared between @code{Senga}
(www.senga.org) and the @code{Ht://dig} Group (dev.htdig.org). Part of
the distribution comes from the @code{Ht://dig} CVS tree and part from
the @code{Senga} CVS tree. The idea is to share efforts between two
development groups that have very similar needs. Since @code{Senga} and
@code{Ht://dig} are both developped under the GPL licence, such
cooperation occurs naturally.

To compile a program using the @code{mifluz} library use something that looks
like the following:

@example
gcc -o word -I/usr/local/include -L/usr/local/lib -lmifluz word.cc
@end example

@node Reference
@chapter Reference


@menu
* htdb_dump::                   
* htdb_stat::                   
* htdb_load::                   
* mifluzdump::                  
* mifluzload::                  
* mifluzsearch::                
* mifluzdict::                  
* WordContext::                 
* WordList::                    
* WordDict::                    
* WordListOne::                 
* WordKey::                     
* WordKeyInfo::                 
* WordType::                    
* WordDBInfo::                  
* WordRecordInfo::              
* WordRecord::                  
* WordReference::               
* WordCursor::                  
* WordCursorOne::               
* WordMonitor::                 
* Configuration::               
* mifluz::                      
@end menu

@node htdb_dump
@section htdb_dump


@menu
* htdb_dump NAME::              
* htdb_dump SYNOPSIS::          
* htdb_dump DESCRIPTION::       
* htdb_dump OPTIONS::           
* htdb_dump ENVIRONMENT::       
@end menu

@node htdb_dump NAME
@subsection htdb_dump NAME


dump the content of an inverted index in Berkeley DB fashion



@node htdb_dump SYNOPSIS
@subsection htdb_dump SYNOPSIS

@example

htdb_dump [-klNpWz] [-S pagesize] [-C cachesize] [-d ahr] [-f file] [-h home] [-s subdb] db_file
@end example


@node htdb_dump DESCRIPTION
@subsection htdb_dump DESCRIPTION


htdb_dump is a slightly modified version of the standard 
Berkeley DB db_dump utility.

The htdb_dump utility reads the database file
@strong{db_file
} and
writes it to the standard output using a portable flat-text format
understood by the
@code{htdb_load
}
utility. The argument
@strong{db_file
} must be a file produced using
the Berkeley DB library functions.



@node htdb_dump OPTIONS
@subsection htdb_dump OPTIONS


@table @samp
@item 
@strong{-W
}

Initialize WordContext(3) before dumping. With the
@strong{-z
}
flag allows to dump inverted indexes using the mifluz(3) specific
compression scheme. The MIFLUZ_CONFIG environment variable must be
set to a file containing the mifluz(3) configuration.
@item 
@strong{-z
}

The
@strong{db_file
} is compressed. If
@strong{-W
} is given the
mifluz(3) specific compression scheme is used. Otherwise the default
gzip compression scheme is used.
@item 
@strong{-d
}

Dump the specified database in a format helpful for debugging
the Berkeley DB library routines.
@table @samp
@item 
a

Display all information.
@item 
h

Display only page headers.
@item 
r

Do not display the free-list or pages on the free list.  This
mode is used by the recovery tests.
@end table
The output format of the
@strong{-d
} option is not standard and may change,
without notice, between releases of the Berkeley DB library.
@item 
@strong{-f
}

Write to the specified
@strong{file
} instead of to the standard output.
@item 
@strong{-h
}

Specify a home directory for the database.
As Berkeley DB versions before 2.0 did not support the concept of a
@code{database home.
}
@item 
@strong{-k
}

Dump record numbers from Queue and Recno databases as keys.
@item 
@strong{-l
}

List the subdatabases stored in the database.
@item 
@strong{-N
}

Do not acquire shared region locks while running.  Other problems such
as potentially fatal errors in Berkeley DB will be ignored as well.  This option
is intended only for debugging errors and should not be used under any
other circumstances.
@item 
@strong{-p
}

If characters in either the key or data items are printing characters
(as defined by
@strong{isprint
}(3)), use printing characters in
@strong{file
} to represent them.  This option permits users to use standard
text editors and tools to modify the contents of databases.

Note, different systems may have different notions as to what characters
are considered
@code{printing characters
}, and databases dumped in
this manner may be less portable to external systems.
@item 
@strong{-s
}

Specify a subdatabase to dump.  If no subdatabase is specified, all
subdatabases found in the database are dumped.
@item 
@strong{-V
}

Write the version number to the standard output and exit.
@end table

Dumping and reloading Hash databases that use user-defined hash functions
will result in new databases that use the default hash function.
While using the default hash function may not be optimal for the new database,
it will continue to work correctly.

Dumping and reloading Btree databases that use user-defined prefix or
comparison functions will result in new databases that use the default
prefix and comparison functions.
@strong{In this case, it is quite likely that the database will be damaged
beyond repair permitting neither record storage or retrieval.
}

The only available workaround for either case is to modify the sources
for the
@code{htdb_load
} utility to load the
database using the correct hash, prefix and comparison functions.



@node htdb_dump ENVIRONMENT
@subsection htdb_dump ENVIRONMENT


@strong{DB_HOME
}
If the
@strong{-h
} option is not specified and the environment variable
DB_HOME is set, it is used as the path of the database home.


@strong{MIFLUZ_CONFIG
}
file name of configuration file read by WordContext(3). Defaults to
@strong{~/.mifluz.
} 



@node htdb_stat
@section htdb_stat


@menu
* htdb_stat NAME::              
* htdb_stat SYNOPSIS::          
* htdb_stat DESCRIPTION::       
* htdb_stat OPTIONS::           
* htdb_stat ENVIRONMENT::       
@end menu

@node htdb_stat NAME
@subsection htdb_stat NAME


displays statistics for Berkeley DB environments.



@node htdb_stat SYNOPSIS
@subsection htdb_stat SYNOPSIS

@example

htdb_stat [-celmNtzW] [-C Acfhlmo] [-d file [-s file]] [-h home] [-M Ahlm]
@end example


@node htdb_stat DESCRIPTION
@subsection htdb_stat DESCRIPTION


htdb_stat is a slightly modified version of the standard Berkeley
DB db_stat utility which displays statistics for Berkeley DB
environments.



@node htdb_stat OPTIONS
@subsection htdb_stat OPTIONS


@table @samp
@item 
@strong{-W
}

Initialize WordContext(3) before gathering statistics. With the
@strong{-z
}
flag allows to gather statistics on inverted indexes generated
with the mifluz(3) specific
compression scheme. The MIFLUZ_CONFIG environment variable must be
set to a file containing the mifluz(3) configuration.
@item 
@strong{-z
}

The
@strong{file
} is compressed. If
@strong{-W
} is given the
mifluz(3) specific compression scheme is used. Otherwise the default
gzip compression scheme is used.
@item 
@strong{-C
}

Display internal information about the lock region.
(The output from this option is often both voluminous and meaningless,
and is intended only for debugging.)
@table @samp
@item 
@strong{A
}

Display all information.
@item 
@strong{c
}

Display lock conflict matrix.
@item 
@strong{f
}

Display lock and object free lists.
@item 
@strong{l
}

Display lockers within hash chains.
@item 
@strong{m
}

Display region memory information.
@item 
@strong{o
}

Display objects within hash chains.
@end table
@item 
@strong{-c
}

Display lock region statistics.
@item 
@strong{-d
}

Display database statistics for the specified database.
If the database contains subdatabases, the statistics
are for the database or subdatabase specified, and not for the database
as a whole.
@item 
@strong{-e
}

Display current environment statistics.
@item 
@strong{-h
}

Specify a home directory for the database.
@item 
@strong{-l
}

Display log region statistics.
@item 
@strong{-M
}

Display internal information about the shared memory buffer pool.
(The output from this option is often both voluminous and meaningless,
and is intended only for debugging.)
@table @samp
@item 
@strong{A
}

Display all information.
@item 
@strong{h
}

Display buffers within hash chains.
@item 
@strong{l
}

Display buffers within LRU chains.
@item 
@strong{m
}

Display region memory information.
@end table
@item 
@strong{-m
}

Display shared memory buffer pool statistics.
@item 
@strong{-N
}

Do not acquire shared region locks while running.  Other problems such
as potentially fatal errors in Berkeley DB will be ignored as well.  This option
is intended only for debugging errors and should not be used under any
other circumstances.
@item 
@strong{-s
}

Display database statistics for the specified subdatabase of the
database specified with the
@strong{-d
} flag.
@item 
@strong{-t
}

Display transaction region statistics.
@item 
@strong{-V
}

Write the version number to the standard output and exit.
@end table

Only one set of statistics is displayed for each run, and the last option
specifying a set of statistics takes precedence.

Values smaller than 10 million are generally displayed without any special
notation.  Values larger than 10 million are normally displayed as
@strong{<number>M
}.

The htdb_stat utility attaches to one or more of the Berkeley DB shared memory
regions.  In order to avoid region corruption, it should always be given
the chance to detach and exit gracefully.  To cause htdb_stat to clean up
after itself and exit, send it an interrupt signal (SIGINT).



@node htdb_stat ENVIRONMENT
@subsection htdb_stat ENVIRONMENT


@strong{DB_HOME
}
If the
@strong{-h
} option is not specified and the environment variable
DB_HOME is set, it is used as the path of the database home.


@strong{MIFLUZ_CONFIG
}
file name of configuration file read by WordContext(3). Defaults to
@strong{~/.mifluz.
} 



@node htdb_load
@section htdb_load


@menu
* htdb_load NAME::              
* htdb_load SYNOPSIS::          
* htdb_load DESCRIPTION::       
* htdb_load OPTIONS::           
* htdb_load KEYWORDS::          
* htdb_load ENVIRONMENT::       
@end menu

@node htdb_load NAME
@subsection htdb_load NAME


displays statistics for Berkeley DB environments.



@node htdb_load SYNOPSIS
@subsection htdb_load SYNOPSIS

@example

htdb_load [-nTzW] [-c name=value] [-f file] [-h home] [-C cachesize] [-t btree | hash | recno] db_file
@end example


@node htdb_load DESCRIPTION
@subsection htdb_load DESCRIPTION


The htdb_load utility reads from the standard input and loads it into
the database
@strong{db_file
}.
The database
@strong{db_file
} is created if it does not already exist.

The input to htdb_load must be in the output format specified by the
htdb_dump utility, or as specified for the
@strong{-T
} below.



@node htdb_load OPTIONS
@subsection htdb_load OPTIONS


@table @samp
@item 
@strong{-W
}

Initialize WordContext(3) before loading. With the
@strong{-z
}
flag allows to load inverted indexes using the mifluz(3) specific
compression scheme. The MIFLUZ_CONFIG environment variable must be
set to a file containing the mifluz(3) configuration.
@item 
@strong{-z
}

The
@strong{db_file
} is compressed. If
@strong{-W
} is given the
mifluz(3) specific compression scheme is used. Otherwise the default
gzip compression scheme is used.
@item 
@strong{-c
}

Specify configuration options for the DB structure 
ignoring any value they may have based on the input.
The command-line format is
@strong{name=value
}.
See
@code{Supported Keywords
} for
a list of supported words for the
@strong{-c
} option.
@item 
@strong{-f
}

Read from the specified
@strong{input
} file instead of from
the standard input.
@item 
@strong{-h
}

Specify a home directory for the database.
If a home directory is specified, the database environment is opened using
the
@code{DB_INIT_LOCK
},
@code{DB_INIT_LOG
},
@code{DB_INIT_MPOOL
},
@code{DB_INIT_TXN
} and
@code{DB_USE_ENVIRON
} flags to
DBENV->open. This means that htdb_load can be used to load
data into databases while they are in use by other processes. If the
DBENV->open call fails, or if no home directory is specified, the
database is still updated, but the environment is ignored, e.g., no
locking is done.
@item 
@strong{-n
}

Do not overwrite existing keys in the database when loading into an
already existing database.
If a key/data pair cannot be loaded into the database for this reason,
a warning message is displayed on the standard error output and the
key/data pair are skipped.
@item 
@strong{-T
}

The
@strong{-T
}
option allows non-Berkeley DB applications to easily load text files 
into databases.

If the database to be created is of type Btree or Hash, or the keyword
@strong{keys
} is specified as set, the input must be paired lines of text,
where the first line of the pair is the key item, and the second line of
the pair is its corresponding data item.  If the database to be created
is of type Queue or Recno and the keywork
@strong{keys
} is not set, the
input must be lines of text, where each line is a new data item for the
database.

A simple escape mechanism, where newline and backslash (\)
characters are special, is applied to the text input.
Newline characters are interpreted as record separators.
Backslash characters in the text will be interpreted in one of two ways:
if the backslash character precedes another backslash character, the pair
will be interpreted as a literal backslash.
If the backslash character precedes any other character, the two characters
following the backslash will be interpreted as hexadecimal specification of
a single character, e.g., \0a is a newline character in the ASCII
character set.

For this reason, any backslash or newline characters that naturally
occur in the text input must be escaped to avoid misinterpretation by
htdb_load

If the
@strong{-T
} option is specified, the underlying access method type
must be specified using the
@strong{-t
} option.
@item 
@strong{-t
}

Specify the underlying access method.
If no
@strong{-t
} option is specified, the database will be loaded into a
database of the same type as was dumped, e.g., a Hash database will be
created if a Hash database was dumped.

Btree and Hash databases may be converted from one to the other.  Queue
and Recno databases may be converted from one to the other.  If the
@strong{-k
} option was specified on the call to htdb_dump then Queue
and Recno databases may be converted to Btree or Hash, with the key being
the integer record number.
@item 
@strong{-V
}

Write the version number to the standard output and exit.
@end table

The htdb_load utility attaches to one or more of the Berkeley DB
shared memory regions.  In order to avoid region corruption, it 
should always be given
the chance to detach and exit gracefully.  To cause htdb_load to clean up
after itself and exit, send it an interrupt signal (SIGINT).

The htdb_load utility exits 0 on success, 1 if one or more key/data
pairs were not loaded into the database because the key already existed,
and >1 if an error occurs.



@node htdb_load KEYWORDS
@subsection htdb_load KEYWORDS


The following keywords are supported for the
@strong{-c
} command-line option
to the htdb_load utility. See DB->open for further discussion of
these keywords and what values should be specified.

The parenthetical listing specifies how the value part of the
@strong{name=value
} pair is interpreted.
Items listed as (boolean) expect value to be
@strong{1
} (set) or
@strong{0
}
(unset).
Items listed as (number) convert value to a number.
Items listed as (string) use the string value without modification.
@table @samp
@item bt_minkey (number)

The minimum number of keys per page.
@item db_lorder (number)

The byte order for integers in the stored database metadata.
@item db_pagesize (number)

The size of pages used for nodes in the tree, in bytes.
@item duplicates (boolean)

The value of the DB_DUP flag.
@item h_ffactor (number)

The density within the Hash database.
@item h_nelem (number)

The size of the Hash database.
@item keys (boolean)

Specify if keys are present for Queue or Recno databases.
@item re_len (number)

Specify fixed-length records of the specified length.
@item re_pad (string)

Specify the fixed-length record pad character.
@item recnum (boolean)

The value of the DB_RECNUM flag.
@item renumber (boolean)

The value of the DB_RENUMBER flag.
@item subdatabase (string)

The subdatabase to load.
@end table



@node htdb_load ENVIRONMENT
@subsection htdb_load ENVIRONMENT


@strong{DB_HOME
}
If the
@strong{-h
} option is not specified and the environment variable
DB_HOME is set, it is used as the path of the database home.


@strong{MIFLUZ_CONFIG
}
file name of configuration file read by WordContext(3). Defaults to
@strong{~/.mifluz.
} 



@node mifluzdump
@section mifluzdump


@menu
* mifluzdump NAME::             
* mifluzdump SYNOPSIS::         
* mifluzdump DESCRIPTION::      
* mifluzdump ENVIRONMENT::      
@end menu

@node mifluzdump NAME
@subsection mifluzdump NAME


dump the content of an inverted index.



@node mifluzdump SYNOPSIS
@subsection mifluzdump SYNOPSIS

@example

mifluzdump file
@end example


@node mifluzdump DESCRIPTION
@subsection mifluzdump DESCRIPTION


mifluzdump writes on
@strong{stdout
} a complete ascii description
of the
@strong{file
} inverted index using the
@code{WordList::Write
}
method. 



@node mifluzdump ENVIRONMENT
@subsection mifluzdump ENVIRONMENT


@strong{MIFLUZ_CONFIG
}
file name of configuration file read by WordContext(3). Defaults to
@strong{~/.mifluz.
} 




@node mifluzload
@section mifluzload


@menu
* mifluzload NAME::             
* mifluzload SYNOPSIS::         
* mifluzload DESCRIPTION::      
* mifluzload ENVIRONMENT::      
@end menu

@node mifluzload NAME
@subsection mifluzload NAME


load the content of an inverted index.



@node mifluzload SYNOPSIS
@subsection mifluzload SYNOPSIS

@example

mifluzload file
@end example


@node mifluzload DESCRIPTION
@subsection mifluzload DESCRIPTION


mifluzload reads from
@strong{stdout
} a complete ascii description
of the
@strong{file
} inverted index using the
@code{WordList::Read
}
method. 



@node mifluzload ENVIRONMENT
@subsection mifluzload ENVIRONMENT


@strong{MIFLUZ_CONFIG
}
file name of configuration file read by WordContext(3). Defaults to
@strong{~/.mifluz.
} 




@node mifluzsearch
@section mifluzsearch


@menu
* mifluzsearch NAME::           
* mifluzsearch SYNOPSIS::       
* mifluzsearch DESCRIPTION::    
* mifluzsearch ENVIRONMENT::    
@end menu

@node mifluzsearch NAME
@subsection mifluzsearch NAME

search the content of an inverted index.



@node mifluzsearch SYNOPSIS
@subsection mifluzsearch SYNOPSIS

@example

mifluzsearch -f words [options]
@end example


@node mifluzsearch DESCRIPTION
@subsection mifluzsearch DESCRIPTION


mifluzsearch searches a mifluz index for documents matching a 
Alt*Vista expression (simple syntax). 

Debugging information interpretation. A cursor is open in the index
for every word and they are stored in a list. The list of cursors
is always processed in the same order, as a single link list. With
-v, each block is an individual action on behalf of the word shown
on the first line. The last line of the block is the conclusion of
the action described in the block. REDO means the same cursor must
be examined again because the conditions have changed. RESTART means
we go back to the first cursor in the list because it may not 
match the new conditions anymore. NEXT means the cursor and all
the cursors before it match the conditions and we may proceed to
the next cursor. ATEND means the cursor cannot match the conditions
because it is at the end of the index.



@node mifluzsearch ENVIRONMENT
@subsection mifluzsearch ENVIRONMENT


@strong{MIFLUZ_CONFIG
}
file name of configuration file read by WordContext(3). Defaults to
@strong{~/.mifluz.
} 




@node mifluzdict
@section mifluzdict


@menu
* mifluzdict NAME::             
* mifluzdict SYNOPSIS::         
* mifluzdict DESCRIPTION::      
* mifluzdict ENVIRONMENT::      
@end menu

@node mifluzdict NAME
@subsection mifluzdict NAME


dump the dictionnary of an inverted index.



@node mifluzdict SYNOPSIS
@subsection mifluzdict SYNOPSIS

@example

mifluzdict file
@end example


@node mifluzdict DESCRIPTION
@subsection mifluzdict DESCRIPTION


mifluzdict writes on
@strong{stdout
} a complete ascii description
of the
@strong{file
} inverted index using the
@code{WordList::Write
}
method. 



@node mifluzdict ENVIRONMENT
@subsection mifluzdict ENVIRONMENT


@strong{MIFLUZ_CONFIG
}
file name of configuration file read by WordContext(3). Defaults to
@strong{~/.mifluz.
} 




@node WordContext
@section WordContext


@menu
* WordContext NAME::            
* WordContext SYNOPSIS::        
* WordContext DESCRIPTION::     
* WordContext CONFIGURATION::   
* WordContext METHODS::         
* WordContext ENVIRONMENT::     
@end menu

@node WordContext NAME
@subsection WordContext NAME


read configuration and setup mifluz context.



@node WordContext SYNOPSIS
@subsection WordContext SYNOPSIS

@example

#include <mifluz.h>

WordContext context;
@end example


@node WordContext DESCRIPTION
@subsection WordContext DESCRIPTION


The WordContext object must be the first object created.
All other objects (WordList, WordReference, WordKey and WordRecord)
are allocated via the corresponding methods of WordContext (List,
Word, Key and Record respectively). 

The WordContext object contains a
@strong{Configuration
} object 
that holds the configuration parameters used by the instance. 
If a configuration parameter is changed, the
@code{ReInitialize
} 
method should be called to take them in account.



@node WordContext CONFIGURATION
@subsection WordContext CONFIGURATION

For more information on the configuration attributes and a complete list of attributes, see the mifluz(3) manual page.
@table @samp
@item  wordlist_monitor @{true|false@} (default false)

 If true create a
@code{WordMonitor
} instance to gather statistics and 
build reports.
@end table


@node WordContext METHODS
@subsection WordContext METHODS

@table @samp
@item   WordContext() 
Constructor. Read the configuration parameters from the
environment.  If the environment variable
@strong{MIFLUZ_CONFIG
} is
set to a pathname, read it as a configuration file. If
@strong{MIFLUZ_CONFIG
} is not set, try to read the
@code{~/.mifluz
}
configuration file or
@code{/usr/etc/mifluz.conf
}. See the mifluz
manual page for a complete list of the configuration attributes.
@item   WordContext(const Configuration &config) 
Constructor. The
@strong{config
} argument must contain all the configuration
parameters, no configuration file is loaded from the environment.
@item   WordContext(const ConfigDefaults *array) 
Constructor. The
@strong{array
} argument holds configuration parameters
that will override their equivalent in the configuration file read 
from the environment.
@item   void Initialize(const Configuration &config)
Initialize the WordContext object. This method is called by 
every constructor.

When calling
@strong{Initialize
} a second time, one must ensure
that all WordList and WordCursor objects have been
destroyed. WordList and WordCursor internal state depends on the
current WordContext that will be lost by a second call.


For those interested by the internals, the
@strong{Initialize
} function
maintains a Berkeley DB environment (DB_ENV) in the following way:

First invocation:
@example
Initialize -> new DB_ENV (thru WordDBInfo)
@end example

Second invocation:
@example
Initialize -> delete DB_ENV -> new DB_ENV (thru WordDBInfo)
@end example
@item   int Initialize(const ConfigDefaults* config_defaults = 0)
Initialize the WordContext object.
Build a
@code{Configuration
} object from the file pointed to by the 
MIFLUZ_CONFIG environment variable or ~/.mifluz or /usr/etc/mifluz.conf.
The
@strong{config_defaults
} argument, if provided, is passed to
the
@code{Configuration
} object using the
@strong{Defaults
} method.
The
@strong{Initialize(const Configuration &)
} method is then called
with the
@code{Configuration
} object.
Return OK if success, NOTOK otherwise.
Refer to the
@code{Configuration
} description for more information.
@item   int ReInitialize()
Destroy internal state except the
@code{Configuration
} object and
rebuild it. May be used when the configuration is changed to
take these changes in account.
Return OK if success, NOTOK otherwise.
@item   const WordType& GetType() const 
Return the
@strong{WordType
} data member of the current object as a const.
@item   WordType& GetType() 
Return the
@strong{WordType
} data member of the current object.
@item   const WordKeyInfo& GetKeyInfo() const 
Return the
@strong{WordKeyInfo
} data member of the current object
as a const.
@item   WordKeyInfo& GetKeyInfo() 
Return the
@strong{WordKeyInfo
} data member of the current object.
@item   const WordRecordInfo& GetRecordInfo() const 
Return the
@strong{WordRecordInfo
} data member of the current
object as a const.
@item   WordRecordInfo& GetRecordInfo() 
Return the
@strong{WordRecordInfo
} data member of the current object.
@item   const WordDBInfo& GetDBInfo() const 
Return the
@strong{WordDBInfo
} data member of the current object as
a const.
@item   WordDBInfo& GetDBInfo() 
Return the
@strong{WordDBInfo
} data member of the current object.
@item   const WordMonitor* GetMonitor() const 
Return the
@strong{WordMonitor
} data member of the current object
as a const.  The pointer may be NULL if the word_monitor
attribute is false.
@item   WordMonitor* GetMonitor() 
Return the
@strong{WordMonitor
} data member of the current object.
The pointer may be NULL if the word_monitor attribute is false.
@item   const Configuration& GetConfiguration() const 
Return the
@strong{Configuration
} data member of the current object
as a const.
@item   Configuration& GetConfiguration() 
Return the
@strong{Configuration
} data member of the current object.
@item   WordList* List()
Return a new
@strong{WordList
} object, using the 
WordList(WordContext*) constructor. It is the responsibility of the
caller to delete this object before the WordContext object is
deleted. Refer to the
@strong{wordlist_multi
} configuration parameter
to know the exact type of the object created.
@item   WordReference* Word()
Return a new
@strong{WordReference
} object, using the
WordReference(WordContext*) constructor. It is the responsibility of the
caller to delete this object before the WordContext object is
deleted.
@item   WordReference* Word(const String& key0, const String& record0)
Return a new
@strong{WordReference
} object, using the
WordReference(WordContext*, const String&, const& String)
constructor. It is the responsibility of the
caller to delete this object before the WordContext object is
deleted.
@item   WordReference* Word(const String& word)
Return a new
@strong{WordReference
} object, using the
WordReference(WordContext*, const String&)
constructor. It is the responsibility of the
caller to delete this object before the WordContext object is
deleted.
@item   WordRecord* Record()
Return a new
@strong{WordRecord
} object, using the
WordRecord(WordContext*) constructor. It is the responsibility of the
caller to delete this object before the WordContext object is
deleted.
@item   WordKey* Key()
Return a new
@strong{WordKey
} object, using the
WordKey(WordContext*) constructor. It is the responsibility of the
caller to delete this object before the WordContext object is
deleted.
@item   WordKey* Key(const String& word)
Return a new
@strong{WordKey
} object, using the
WordKey(WordContext*, const String&) constructor. It is the
responsibility of the caller to delete this object before the
WordContext object is deleted.
@item   WordKey* Key(const WordKey& other)
Return a new
@strong{WordKey
} object, using the
WordKey(WordContext*, const WordKey&) constructor. It is the
responsibility of the caller to delete this object before the
WordContext object is deleted.
@item   static String ConfigFile()
Return the full pathname of the configuration file. The configuration
file lookup first searches for the file pointed by the
@strong{MIFLUZ_CONFIG
} environment variable then
@strong{~/.mifluz
} and
finally
@strong{/usr/etc/mifluz.conf
}. If no configuration file is found,
return the empty string.
@end table


@node WordContext ENVIRONMENT
@subsection WordContext ENVIRONMENT


@strong{MIFLUZ_CONFIG
} file name of configuration file read by
WordContext(3). Defaults to
@strong{~/.mifluz.
} or
@strong{/usr/etc/mifluz.conf
}



@node WordList
@section WordList


@menu
* WordList NAME::               
* WordList SYNOPSIS::           
* WordList DESCRIPTION::        
* WordList CONFIGURATION::      
* WordList METHODS::            
@end menu

@node WordList NAME
@subsection WordList NAME


abstract class to manage and use an inverted index file.



@node WordList SYNOPSIS
@subsection WordList SYNOPSIS

@example

#include <mifluz.h>

WordContext context;

WordList* words = context->List();

delete words;
@end example


@node WordList DESCRIPTION
@subsection WordList DESCRIPTION


WordList is the
@code{mifluz
} equivalent of a database handler. Each
WordList object is bound to an inverted index file and implements the
operations to create it, fill it with word occurrences and search 
for an entry matching a given criterion.

WordList is an abstract class and cannot be instanciated. 
The
@strong{List
} method of the class WordContext will create 
an instance using the appropriate derived class, either WordListOne
or WordListMulti. Refer to the corresponding manual pages for
more information on their specific semantic.

When doing bulk insertions, mifluz creates temporary files that
contain the entries to be inserted in the index. Those files are
typically named
@code{indexC00000000
}. The maximum size of the 
temporary file is
@strong{wordlist_cache_size
} / 2. When the maximum
size of the temporary file is reached, mifluz creates another temporary
file named
@code{indexC00000001
}. The process continues until mifluz
created 50 temporary file. At this point it merges all temporary files
into one that replaces the first
@code{indexC00000000
}. Then it continues
to create temporary file again and keeps following this algorithm until
the bulk insertion is finished. When the bulk insertion is finished,
mifluz has one big file named
@code{indexC00000000
} that contains
all the entries to be inserted in the index. mifluz inserts all the
entries from
@code{indexC00000000
} into the index and delete the 
temporary file when done. The insertion will be fast since all the
entries in
@code{indexC00000000
} are already sorted. 

The parameter
@strong{wordlist_cache_max
} can be used to prevent the
temporary files to grow indefinitely. If the total cumulated size of
the
@code{indexC*
} files grow beyond this parameter, they are merged
into the main index and deleted. For instance setting this parameter
value to 500Mb garanties that the total size of the
@code{indexC*
} 
files will not grow above 500Mb.



@node WordList CONFIGURATION
@subsection WordList CONFIGURATION

For more information on the configuration attributes and a complete list of attributes, see the mifluz(3) manual page.
@table @samp
@item  wordlist_extend @{true|false@} (default false)

 If
@strong{true
} maintain reference count of unique 
words. The
@strong{Noccurrence
} method gives access to this count.
@item  wordlist_verbose <number> (default 0)

 Set the verbosity level of the WordList class.


1 walk logic


2 walk logic details


3 walk logic lots of details
@item  wordlist_page_size <bytes> (default 8192)

 Berkeley DB page size (see Berkeley DB documentation)
@item  wordlist_cache_size <bytes> (default 500K)

 Berkeley DB cache size (see Berkeley DB documentation)
Cache makes a huge difference in performance. It must be at least 2%
of the expected total data size. Note that if compression is activated
the data size is eight times larger than the actual file size. In this
case the cache must be scaled to 2% of the data size, not 2% 
of the file size. See
@strong{Cache tuning
} in the mifluz guide for
more hints.
See WordList(3) for the rationale behind cache file handling.
@item  wordlist_cache_max <bytes> (default 0)

 Maximum size of the cumulated cache files generated when doing bulk
insertion with the
@strong{BatchStart()
} function. When this limit is
reached, the cache files are all merged into the inverted index. 
The value 0 means infinite size allowed.
See WordList(3) for the rationale behind cache file handling.
@item  wordlist_cache_inserts @{true|false@} (default false)

 If true all
@strong{Insert
} calls are cached in memory. When the 
WordList object is closed or a different access method is called
the cached entries are flushed in the inverted index.
@item  wordlist_compress @{true|false@} (default false)

 Activate compression of the index. The resulting index is eight times
smaller than the uncompressed index.
@end table


@node WordList METHODS
@subsection WordList METHODS

@table @samp
@item   inline WordContext* GetContext() 
Return a pointer to the WordContext object used to create
this instance.
@item   inline const WordContext* GetContext() const 
Return a pointer to the WordContext object used to create
this instance as a const.
@item   virtual inline int Override(const WordReference& wordRef) 
Insert
@strong{wordRef
} in index. If the
@code{Key()
} part of
the
@strong{wordRef
} exists in the index, override it.
Returns OK on success, NOTOK on error.
@item   virtual int Exists(const WordReference& wordRef) 
Returns OK if
@strong{wordRef
} exists in the index, NOTOK otherwise.
@item   inline int Exists(const String& word) 
Returns OK if
@strong{word
} exists in the index, NOTOK otherwise.
@item   virtual int WalkDelete(const WordReference& wordRef) 
Delete all entries in the index whose key matches the
@code{Key()
} part of
@strong{wordRef
}, using the
@code{Walk
}
method.
Returns the number of entries successfully deleted.
@item   virtual int Delete(const WordReference& wordRef) 
Delete the entry in the index that exactly matches the
@code{Key()
} part of
@strong{wordRef.
}
Returns OK if deletion is successfull, NOTOK otherwise.
@item   virtual int Open(const String& filename, int mode) 
Open inverted index
@strong{filename.
}
@strong{mode
}
may be
@code{O_RDONLY
} or
@code{O_RDWR.
} If mode is
@code{O_RDWR
} it can be or'ed with
@code{O_TRUNC
} to reset
the content of an existing inverted index.
Return OK on success, NOTOK otherwise.
@item   virtual int Close() 
Close inverted index.
Return OK on success, NOTOK otherwise.
@item   virtual unsigned int Size() const 
Return the size of the index in pages.
@item   virtual int Pagesize() const 
Return the page size
@item   virtual WordDict *Dict() 
Return a pointer to the inverted index dictionnary.
@item   const String& Filename() const 
Return the filename given to the last call to Open.
@item   int Flags() const 
Return the mode given to the last call to Open.
@item   inline List *Find(const WordReference& wordRef) 
Returns the list of word occurrences exactly matching the
@code{Key()
} part of
@strong{wordRef.
} The
@code{List
} returned
contains pointers to
@code{WordReference
} objects. It is
the responsibility of the caller to free the list. See List.h
header for usage.
@item   inline List *FindWord(const String& word) 
Returns the list of word occurrences exactly matching the
@strong{word.
} The
@code{List
} returned
contains pointers to
@code{WordReference
} objects. It is
the responsibility of the caller to free the list. See List.h
header for usage.
@item   virtual List *operator [] (const WordReference& wordRef) 
Alias to the
@strong{Find
} method.
@item   inline List *operator [] (const String& word) 
Alias to the
@strong{FindWord
} method.
@item   virtual List *Prefix (const WordReference& prefix) 
Returns the list of word occurrences matching the
@code{Key()
}
part of
@strong{wordRef.
} In the
@code{Key()
}, the string
(accessed with
@code{GetWord()
}) matches any string that begins
with it. The
@code{List
} returned contains pointers to
@code{WordReference
} objects. It is the responsibility of the
caller to free the list.
@item   inline List *Prefix (const String& prefix) 
Returns the list of word occurrences matching the
@strong{word.
} In the
@code{Key()
}, the string (accessed with
@code{GetWord()
}) matches any string that begins with it. The
@code{List
} returned contains pointers to
@code{WordReference
}
objects. It is the responsibility of the caller to free the
list.
@item   virtual List *Words() 
Returns a list of all unique words contained in the inverted
index. The
@code{List
} returned contains pointers to
@code{String
} objects. It is the responsibility of the caller
to free the list. See List.h header for usage.
@item   virtual List *WordRefs() 
Returns a list of all entries contained in the
inverted index. The
@code{List
} returned contains pointers to
@code{WordReference
} objects. It is the responsibility of
the caller to free the list. See List.h header for usage.
@item   virtual WordCursor *Cursor(wordlist_walk_callback_t callback, Object *callback_data) 
Create a cursor that searches all the occurrences in the
inverted index and call
@strong{ncallback
} with
@strong{ncallback_data
} for every match.
@item   virtual WordCursor *Cursor(const WordKey &searchKey, int action = HTDIG_WORDLIST_WALKER) 
Create a cursor that searches all the occurrences in the
inverted index and that match
@strong{nsearchKey.
} If
@strong{naction
} is set to HTDIG_WORDLIST_WALKER calls
@strong{searchKey.callback
} with
@strong{searchKey.callback_data
}
for every match. If
@strong{naction
} is set to
HTDIG_WORDLIST_COLLECT push each match in
@strong{searchKey.collectRes
}
data member as a
@strong{WordReference
} object. It is the responsibility
of the caller to free the
@strong{searchKey.collectRes
} list.
@item   virtual WordCursor *Cursor(const WordKey &searchKey, wordlist_walk_callback_t callback, Object * callback_data) 
Create a cursor that searches all the occurrences in the
inverted index and that match
@strong{nsearchKey
} and calls
@strong{ncallback
} with
@strong{ncallback_data
} for every match.
@item   virtual WordKey Key(const String& bufferin) 
Create a WordKey object and return it. The
@strong{bufferin
} argument
is used to initialize the key, as in the WordKey::Set method. 
The first component of
@strong{bufferin
} must be a word that is translated
to the corresponding numerical id using the WordDict::Serial
method.
@item   virtual WordReference Word(const String& bufferin, int exists = 0) 
Create a WordReference object and return it. The
@strong{bufferin
} argument is used to initialize the structure,
as in the WordReference::Set method.  The first component of
@strong{bufferin
} must be a word that is translated to the
corresponding numerical id using the WordDict::Serial method.
If the
@strong{exists
} argument is set to 1, the method 
WordDict::SerialExists is used instead, that is no serial is
assigned to the word if it does not already have one.
Before translation the word is normalized using the
WordType::Normalize method. The word is saved using the
WordReference::SetWord method.
@item   virtual WordReference WordExists(const String& bufferin) 
Alias for Word(bufferin, 1).
@item   virtual void BatchStart()
Accelerate bulk insertions in the inverted index. All 
insertion done with the
@strong{Override
} method are batched
instead of being updating the inverted index immediately.
No update of the inverted index file is done before the
@strong{BatchEnd
} method is called.
@item   virtual void BatchEnd()
Terminate a bulk insertion started with a call to the
@strong{BatchStart
} method. When all insertions are done
the
@strong{AllRef
} method is called to restore statistics.
@item   virtual int Noccurrence(const String& key, unsigned int& noccurrence) const 
Return in
@strong{noccurrence
} the number of occurrences of the
string contained in the
@code{GetWord()
} part of
@strong{key.
}
Returns OK on success, NOTOK otherwise.
@item   virtual int Write(FILE* f) 
Write on file descriptor
@strong{f
} an ASCII description of the
index. Each line of the file contains a
@code{WordReference
}
ASCII description.
Return OK on success, NOTOK otherwise.
@item   virtual int WriteDict(FILE* f) 
Write on file descriptor
@strong{f
} the complete dictionnary 
with statistics.
Return OK on success, NOTOK otherwise.
@item   virtual int Read(FILE* f) 
Read
@code{WordReference
} ASCII descriptions from
@strong{f
},
returns the number of inserted WordReference or < 0 if an error
occurs. Invalid descriptions are ignored as well as empty
lines.
@end table


@node WordDict
@section WordDict


@menu
* WordDict NAME::               
* WordDict SYNOPSIS::           
* WordDict DESCRIPTION::        
* WordDict METHODS::            
@end menu

@node WordDict NAME
@subsection WordDict NAME


manage and use an inverted index dictionary.



@node WordDict SYNOPSIS
@subsection WordDict SYNOPSIS

@example

#include <mifluz.h>

WordList* words = ...;
WordDict* dict = words->Dict();
@end example


@node WordDict DESCRIPTION
@subsection WordDict DESCRIPTION


WordDict maps strings to unique identifiers and frequency in the 
inverted index. Whenever a new word is found, the WordDict class 
can be asked to assign it a serial number. When doing so, an entry
is created in the dictionary with a frequency of zero. The application
may then increment or decrement the frequency to reflect the inverted
index content.

The serial numbers range from 1 to 2^32 inclusive.

A WordDict object is automatically created by the WordList object and
should not be created directly by the application.



@node WordDict METHODS
@subsection WordDict METHODS

@table @samp
@item   WordDict() 
Private constructor.
@item   int Initialize(WordList* words)
Bind the object a WordList inverted index. Return OK on success,
NOTOK otherwise.
@item   int Open()
Open the underlying Berkeley DB sub-database. The enclosing 
file is given by the
@code{words
} data member. Return OK on success,
NOTOK otherwise.
@item   int Remove()
Destroy the underlying Berkeley DB sub-database. Return OK on success,
NOTOK otherwise.
@item   int Close()
Close the underlying Berkeley DB sub-database. Return OK on success,
NOTOK otherwise.
@item   int Serial(const String& word, unsigned int& serial)
If the
@strong{word
} argument exists in the dictionnary, return its
serial number in the
@strong{serial
} argument. If it does not already
exists, assign it a serial number, create an entry with a frequency
of zero and return the new serial in the
@strong{serial
} argument.
Return OK on success, NOTOK otherwise.
@item   int SerialExists(const String& word, unsigned int& serial)
If the
@strong{word
} argument exists in the dictionnary, return its
serial number in the
@strong{serial
} argument. If it does not exists
set the
@strong{serial
} argument to WORD_DICT_SERIAL_INVALID.
Return OK on success, NOTOK otherwise.
@item   int SerialRef(const String& word, unsigned int& serial)
Short hand for Serial() followed by Ref().
Return OK on success, NOTOK otherwise.
@item   int Noccurrence(const String& word, unsigned int& noccurrence) const
Return the frequency of the
@strong{word
} argument
in the
@strong{noccurrence
} argument. 
Return OK on success, NOTOK otherwise.
@item   int Normalize(String& word) const
Short hand for words->GetContext()->GetType()->Normalize(word).
Return OK on success, NOTOK otherwise.
@item   int Ref(const String& word) 
Short hand for Incr(word, 1)
@item   int Incr(const String& word, unsigned int incr)
Add
@strong{incr
} to the frequency of the
@strong{word
}. 
Return OK on success, NOTOK otherwise.
@item   int Unref(const String& word) 
Short hand for Decr(word, 1)
@item   int Decr(const String& word, unsigned int decr)
Subtract
@strong{decr
} to the frequency of the
@strong{word
}. If
the frequency becomes lower or equal to zero, remove the entry
from the dictionnary and lose the association between the word and its
serial number.
Return OK on success, NOTOK otherwise.
@item   int Put(const String& word, unsigned int noccurrence)
Set the frequency of
@strong{word
} with the value of the
@strong{noccurrence
}
argument.
@item   int Exists(const String& word) const
Return true if
@strong{word
} exists in the dictionnary, false otherwise.
@item   List* Words() const
Return a pointer to the associated WordList object.
@item   WordDictCursor* Cursor() const
Return a cursor to sequentially walk the dictionnary using the
@strong{Next
} method.
@item   int Next(WordDictCursor* cursor, String& word, WordDictRecord& record)
Return the next entry in the dictionnary. The
@strong{cursor
} argument
must have been created using the
@code{Cursor
} method. The word is
returned in the
@strong{word
} argument and the record is returned in
the
@strong{record
} argument. 
On success the function returns 0, at the end of the dictionnary it
returns DB_NOTFOUND. The
@strong{cursor
} argument is deallocated when
the function hits the end of the dictionnary or an error occurs.
@item   WordDictCursor* CursorPrefix(const String& prefix) const
Return a cursor to sequentially walk the entries of the dictionnary
that start with the
@strong{prefix
} argument, using the
@strong{NextPrefix
} method.
@item   int NextPrefix(WordDictCursor* cursor, String& word, WordDictRecord& record)
Return the next prefix from the dictionnary. The
@strong{cursor
} argument
must have been created using the
@code{CursorPrefix
} method. The word is
returned in the
@strong{word
} argument and the record is returned in
the
@strong{record
} argument. The
@strong{word
} is guaranteed to start with
the prefix specified to the
@strong{CursorPrefix
} method.
On success the function returns 0, at the end of the dictionnary it
returns DB_NOTFOUND. The
@strong{cursor
} argument is deallocated when
the function hits the end of the dictionnary or an error occurs.
@item   int Write(FILE* f)
Dump the complete dictionary in the file descriptor
@strong{f.
} The
format of the dictionary is
@code{word serial frequency
}, one by
line.
@end table


@node WordListOne
@section WordListOne


@menu
* WordListOne NAME::            
* WordListOne SYNOPSIS::        
* WordListOne DESCRIPTION::     
* WordListOne METHODS::         
@end menu

@node WordListOne NAME
@subsection WordListOne NAME


manage and use an inverted index file.



@node WordListOne SYNOPSIS
@subsection WordListOne SYNOPSIS

@example

#include <mifluz.h>

WordContext context;

WordList* words = context->List();
WordList* words = WordListOne(context)
@end example


@node WordListOne DESCRIPTION
@subsection WordListOne DESCRIPTION


WordList is the
@code{mifluz
} equivalent of a database handler. Each
WordList object is bound to an inverted index file and implements the
operations to create it, fill it with word occurrences and search 
for an entry matching a given criterion.

The general behavious of WordListOne is described in the WordList
manual page. It is prefered to create a WordListOne instance by
setting the
@code{wordlist_multi
} configuration parameter to false
and calling the
@strong{WordContext::List
} method. 

Only the methods that differ from WordList are listed here.
All the methods of WordList are implemented by WordListOne and
you should refer to the manual page for more information.

The
@strong{Cursor
} methods all return a WordCursorOne instance
cast to a WordCursor object.



@node WordListOne METHODS
@subsection WordListOne METHODS

@table @samp
@item   WordListOne(WordContext* ncontext)
Constructor. Build inverted index handling object using
run time configuration parameters listed in the
@strong{CONFIGURATION
}
section of the
@strong{WordList
} manual page.
@item   int DeleteCursor(WordDBCursor& cursor) 
Delete the inverted index entry currently pointed to by the
@strong{cursor.
} 
Returns 0 on success, Berkeley DB error code on error. This
is mainly useful when implementing a callback function for
a
@strong{WordCursor.
}
@end table


@node WordKey
@section WordKey


@menu
* WordKey NAME::                
* WordKey SYNOPSIS::            
* WordKey DESCRIPTION::         
* WordKey ASCII FORMAT::        
* WordKey METHODS::             
@end menu

@node WordKey NAME
@subsection WordKey NAME

inverted index key.



@node WordKey SYNOPSIS
@subsection WordKey SYNOPSIS

@example

#include <WordKey.h>

#define WORD_KEY_DOCID    1
#define WORD_KEY_LOCATION 2

WordList* words = ...;
WordKey key = words->Key("word 100 20");
WordKey searchKey;
words->Dict()->SerialExists("dog", searchKey.Get(WORD_KEY_WORD));
searchKey.Set(WORD_KEY_LOCATION, 5);
WordCursor* cursor = words->Key(searchKey);
@end example


@node WordKey DESCRIPTION
@subsection WordKey DESCRIPTION


Describes the key used to store a entry in the inverted index.
Each field in the key has a bit in the
@strong{set
}
member that says if it is set or not. This bit allows to
say that a particular field is
@code{undefined
} regardless of
the actual value stored. The methods
@strong{IsDefined, SetDefined
} and
@strong{Undefined
} are used to manipulate
the
@code{defined
} status of a field. The
@strong{Pack
} and
@strong{Unpack
}
methods are used to convert to and from the disk storage representation
of the key. 

Although constructors may be used, the prefered way to create a 
WordKey object is by using the
@strong{WordContext::Key
} method.

The following constants are defined:
@table @samp
@item  WORD_KEY_WORD

 the index of the word identifier with the key for Set and Get
methods.
@item  WORD_KEY_VALUE_INVALID

 a value that is invalid for any field of the key.
@end table



@node WordKey ASCII FORMAT
@subsection WordKey ASCII FORMAT


The ASCII description is a string with fields separated by tabs or
white space.
@example
Example: 200 <UNDEF> 1 4 2
Field 1: The word identifier or <UNDEF> if not defined
Field 2 to the end: numerical value of the field or <UNDEF> if
                    not defined
@end example



@node WordKey METHODS
@subsection WordKey METHODS

@table @samp
@item   WordKey(WordContext* ncontext) 
Constructor. Build an empty key.
The
@strong{ncontext
} argument must be a pointer to a valid
WordContext object.
@item   WordKey(WordContext* ncontext, const String& desc) 
Constructor. Initialize from an ASCII description of a key.
See
@code{ASCII FORMAT
} section.
The
@strong{ncontext
} argument must be a pointer to a valid
WordContext object.
@item   void Clear() 
Reset to empty key.
@item   inline int NFields() const 
Convenience functions to access the total number of fields
in a key (see
@code{WordKeyInfo(3)
}).
@item   inline WordKeyNum MaxValue(int position) 
Convenience functions to access the 
maximum possible value for field at
@strong{position.
}
in a key (see
@code{WordKeyInfo(3)
}).
@item   inline WordContext* GetContext() 
Return a pointer to the WordContext object used to create
this instance.
@item   inline const WordContext* GetContext() const 
Return a pointer to the WordContext object used to create
this instance as a const.
@item   inline WordKeyNum Get(int position) const 
Return value of numerical field at
@strong{position
} as const.
@item   inline WordKeyNum& Get(int position) 
Return value of numerical field at
@strong{position.
}
@item   inline const WordKeyNum & operator[] (int position) const 
Return value of numerical field at
@strong{position
} as const.
@item   inline WordKeyNum & operator[] (int position) 
Return value of numerical field at
@strong{position.
}
@item   inline void Set(int position, WordKeyNum val) 
Set value of numerical field at
@strong{position
} to
@strong{val.
}
@item   int IsDefined(int position) const 
Returns true if field at
@strong{position
} is
@code{defined
}, false
otherwise.
@item   void SetDefined(int position) 
Value in field
@strong{position
} becomes
@code{defined.
} A bit
is set in the bit field describing the defined/undefined state
of the value and the actual value of the field is not modified.
@item   void Undefined(int position) 
Value in field
@strong{position
} becomes
@code{undefined.
} A bit
is set in the bit field describing the defined/undefined state
of the value and the actual value of the field is not modified.
@item   int Set(const String& bufferin)
Set the whole structure from ASCII string in
@strong{bufferin.
}
See
@code{ASCII FORMAT
} section.
Return OK if successfull, NOTOK otherwise.
@item   int Get(String& bufferout) const
Convert the whole structure to an ASCII string description 
in
@strong{bufferout.
}
See
@code{ASCII FORMAT
} section.
Return OK if successfull, NOTOK otherwise.
@item   String Get() const
Convert the whole structure to an ASCII string description 
and return it.
See
@code{ASCII FORMAT
} section.
@item   int Unpack(const char* string, int length)
Set structure from disk storage format as found in
@strong{string
} buffer or length
@strong{length.
}
Return OK if successfull, NOTOK otherwise.
@item   inline int Unpack(const String& data) 
Set structure from disk storage format as found in
@strong{data
} string.
Return OK if successfull, NOTOK otherwise.
@item   int Pack(String& data) const
Convert object into disk storage format as found in 
and place the result in
@strong{data
} string.
Return OK if successfull, NOTOK otherwise.
@item   int Merge(const WordKey& other)
Copy each
@code{defined
} field from other into the object, if 
the corresponding field of the object is not defined. 
Return OK if successfull, NOTOK otherwise.
@item   int PrefixOnly()
Undefine all fields found after the first undefined field. The
resulting key has a set of defined fields followed by undefined fields.
Returns NOTOK if the word is not defined because the resulting key would 
be empty and this is considered an error. Returns OK on success.
@item   int SetToFollowing(int position = WORD_FOLLOWING_MAX)
Implement ++ on a key.

It behaves like arithmetic but follows these rules:
@example
. Increment starts at field <position>
. If a field value overflows, increment field
@strong{position
} - 1
. Undefined fields are ignored and their value untouched
. When a field is incremented all fields to the left are set to 0
@end example
If position is not specified it is equivalent to NFields() - 1.
It returns OK if successfull, NOTOK if
@strong{position
} out of range or
WORD_FOLLOWING_ATEND if the maximum possible value was reached.
@item   int Filled() const 
Return true if all the fields are
@code{defined
}, false otherwise.
@item   int Empty() const 
Return true if no fields are
@code{defined
}, false otherwise.
@item   int Equal(const WordKey& other) const
Return true if the object and
@strong{other
} are equal. 
Only fields defined in both keys are compared.
@item   int ExactEqual(const WordKey& other) const 
Return true if the object and
@strong{other
} are equal. 
All fields are compared. If a field is defined in
@strong{object
}
and not defined in the object, the key are not considered
equal.
@item   int Cmp(const WordKey& other) const
Compare
@strong{object
} and
@strong{other
} as in strcmp. Undefined
fields are ignored. Returns a positive number if
@strong{object
} is
greater than
@strong{other
}, zero if they are equal, a negative
number if
@strong{object
} is lower than
@strong{other.
}
@item   int PackEqual(const WordKey& other) const
Return true if the object and
@strong{other
} are equal. 
The packed string are compared. An
@code{undefined
} numerical field 
will be 0 and therefore undistinguishable from a
@code{defined
} field
whose value is 0.
@item   int Outbound(int position, int increment) 
Return true if adding
@strong{increment
} in field at
@strong{position
} makes
it overflow or underflow, false if it fits.
@item   int Overflow(int position, int increment) 
Return true if adding positive
@strong{increment
} to field at
@strong{position
} makes it overflow, false if it fits.
@item   int Underflow(int position, int increment) 
Return true if subtracting positive
@strong{increment
} to field 
at
@strong{position
} makes it underflow, false if it fits.
@item   int Prefix() const
Return OK if the key may be used as a prefix for search.
In other words return OK if the fields set in the key
are all contiguous, starting from the first field.
Otherwise returns NOTOK
@item   static int Compare(WordContext* context, const String& a, const String& b)
Compare
@strong{a
} and
@strong{b
} in the Berkeley DB fashion.
@strong{a
} and
@strong{b
} are packed keys. The semantics of the
returned int is as of strcmp and is driven by the key description
found in
@code{WordKeyInfo.
} Returns a positive number if
@strong{a
} is
greater than
@strong{b
}, zero if they are equal, a negative number 
if
@strong{a
} is lower than
@strong{b.
}
@item   static int Compare(WordContext* context, const unsigned char *a, int a_length, const unsigned char *b, int b_length)
Compare
@strong{a
} and
@strong{b
} in the Berkeley DB fashion.
@strong{a
} and
@strong{b
} are packed keys. The semantics of the
returned int is as of strcmp and is driven by the key description
found in
@code{WordKeyInfo.
} Returns a positive number if
@strong{a
} is
greater than
@strong{b
}, zero if they are equal, a negative number 
if
@strong{a
} is lower than
@strong{b.
}
@item   int Diff(const WordKey& other, int& position, int& lower)
Compare object defined fields with
@strong{other
} key defined fields only,
ignore fields that are not defined in object or
@strong{other.
} 
Return 1 if different 0 if equal. 
If different,
@strong{position
} is set to the field number that differ,
@strong{lower
} is set to 1 if Get(
@strong{position
}) is lower than
other.Get(
@strong{position
}) otherwise lower is set to 0.
@item   int Write(FILE* f) const
Print object in ASCII form on
@strong{f
} (uses
@code{Get
} method).
See
@code{ASCII FORMAT
} section.
@item   void Print() const
Print object in ASCII form on
@strong{stdout
} (uses
@code{Get
} method).
See
@code{ASCII FORMAT
} section.
@end table


@node WordKeyInfo
@section WordKeyInfo


@menu
* WordKeyInfo NAME::            
* WordKeyInfo SYNOPSIS::        
* WordKeyInfo DESCRIPTION::     
* WordKeyInfo CONFIGURATION::   
@end menu

@node WordKeyInfo NAME
@subsection WordKeyInfo NAME

information on the key structure of the inverted index.



@node WordKeyInfo SYNOPSIS
@subsection WordKeyInfo SYNOPSIS

@example

Helper for the WordKey class.
@end example


@node WordKeyInfo DESCRIPTION
@subsection WordKeyInfo DESCRIPTION


Describe the structure of the index key (
@code{WordKey
}).
The description includes the layout of the packed version
stored on disk.



@node WordKeyInfo CONFIGURATION
@subsection WordKeyInfo CONFIGURATION

For more information on the configuration attributes and a complete list of attributes, see the mifluz(3) manual page.
@table @samp
@item  wordlist_wordkey_description <desc> (no default)

 Describe the structure of the inverted index key.
In the following explanation of the
@code{<desc>
} format,
mandatory words are
in bold and values that must be replaced in italic.


@strong{Word
}
@code{bits/name bits
}[/...]


The
@code{name
} is an alphanumerical symbolic name for the key field.
The
@code{bits
} is the number of bits required to store this field.
Note that all values are stored in unsigned integers (unsigned int).
Example:
@example
Word 8/Document 16/Location 8
@end example
@end table


@node WordType
@section WordType


@menu
* WordType NAME::               
* WordType SYNOPSIS::           
* WordType DESCRIPTION::        
* WordType CONFIGURATION::      
* WordType METHODS::            
@end menu

@node WordType NAME
@subsection WordType NAME

defines a word in term of allowed characters, length etc.



@node WordType SYNOPSIS
@subsection WordType SYNOPSIS

@example

Only called thru WordContext::Initialize()
@end example


@node WordType DESCRIPTION
@subsection WordType DESCRIPTION


WordType defines an indexed word and operations to validate
a word to be indexed. All words inserted into the
@code{mifluz
} index
are
@strong{Normalize
}d before insertion. The configuration options
give some control over the definition of a word.



@node WordType CONFIGURATION
@subsection WordType CONFIGURATION

For more information on the configuration attributes and a complete list of attributes, see the mifluz(3) manual page.
@table @samp
@item  wordlist_locale <locale> (default C)

 Set the locale of the program to
@strong{locale
}. See setlocale(3)
for more information.
@item  wordlist_allow_numbers @{true|false@} <number> (default false)

 A digit is considered a valid character within a word if
this configuration parameter is set to
@code{true
} otherwise
it is an error to insert a word containing digits.
See the
@strong{Normalize
} method for more information.
@item  wordlist_mimimun_word_length <number> (default 3)

 The minimum length of a word.
See the
@strong{Normalize
} method for more information.
@item  wordlist_maximum_word_length <number> (default 25)

 The maximum length of a word.
See the
@strong{Normalize
} method for more information.
@item  wordlist_allow_numbers @{true|false@} <number> (default false)

 A digit is considered a valid character within a word if
this configuration parameter is set to
@code{true
} otherwise
it is an error to insert a word containing digits.
See the
@strong{Normalize
} method for more information.
@item  wordlist_truncate @{true|false@} <number> (default true)

 If a word is too long according to
the
@code{wordlist_maximum_word_length
} it is truncated
if this configuration parameter is
@code{true
} otherwise it
is considered an invalid word.
@item  wordlist_lowercase @{true|false@} <number> (default true)

 If a word contains upper case letters it is converted to lowercase
if this configuration parameter is true, otherwise it is left
untouched.
@item  wordlist_valid_punctuation [characters] (default none)

 A list of punctuation characters that may appear in a word. 
These characters will be removed from the word before insertion
in the index.
@end table


@node WordType METHODS
@subsection WordType METHODS

@table @samp
@item   int Normalize(String &s) const
Normalize a word according to configuration specifications and 
builtin transformations.
@strong{Every
} word inserted in the inverted
index goes thru this function. If
a word is rejected (return value has WORD_NORMALIZE_NOTOK bit set) it will not 
be inserted in the index. If a word is accepted (return value has 
WORD_NORMALIZE_OK bit set) it will be inserted in the index. In
addition to these two bits, informational values are stored that
give information on the processing done on the word.
The bit field values and their meanings are
as follows:
@table @samp
@item WORD_NORMALIZE_TOOLONG

the word length exceeds the value of 
    the
@code{wordlist_maximum_word_length
} configuration parameter.
@item WORD_NORMALIZE_TOOSHORT

the word length is smaller than the value of 
    the
@code{wordlist_minimum_word_length
} configuration parameter.
@item WORD_NORMALIZE_CAPITAL

the word contained capital letters and has been converted 
    to lowercase. This bit is only set
    if the
@code{wordlist_lowercase
} configuration parameter
    is true.
@item WORD_NORMALIZE_NUMBER

the word contains digits and the configuration 
    parameter
@code{wordlist_allow_numbers
} is set to false.
@item WORD_NORMALIZE_CONTROL

the word contains control characters.
@item WORD_NORMALIZE_BAD

the word is listed in the file pointed by 
    the
@code{wordlist_bad_word_list
} configuration parameter.
@item WORD_NORMALIZE_NULL

the word is a zero length string.
@item WORD_NORMALIZE_PUNCTUATION

at least one character listed in 
    the
@code{wordlist_valid_punctuation
} attribute was removed
    from the word.
@item WORD_NORMALIZE_NOALPHA

the word does not contain any alphanumerical character.
@end table
@item   static String NormalizeStatus(int flags)
Returns a string explaining the return flags of the Normalize
method.
@end table


@node WordDBInfo
@section WordDBInfo


@menu
* WordDBInfo NAME::             
* WordDBInfo SYNOPSIS::         
* WordDBInfo DESCRIPTION::      
* WordDBInfo CONFIGURATION::    
@end menu

@node WordDBInfo NAME
@subsection WordDBInfo NAME

inverted index usage environment.



@node WordDBInfo SYNOPSIS
@subsection WordDBInfo SYNOPSIS

@example

Only called thru WordContext::Initialize()
@end example


@node WordDBInfo DESCRIPTION
@subsection WordDBInfo DESCRIPTION


The inverted indexes may be shared among processes/threads and provide the
appropriate locking to prevent mistakes. In addition the memory cache
used by
@code{WordList
} objects may be shared by processes/threads, 
greatly reducing the memory needs in multi-process applications.
For more information about the shared environment, check the Berkeley
DB documentation.



@node WordDBInfo CONFIGURATION
@subsection WordDBInfo CONFIGURATION

For more information on the configuration attributes and a complete list of attributes, see the mifluz(3) manual page.
@table @samp
@item  wordlist_env_skip @{true,false@} (default false)

 If true no environment is created at all. This must never 
be used if a
@code{WordList
} object is created. It may be
useful if only
@code{WordKey
} objects are used, for instance.
@item  wordlist_env_share @{true,false@} (default false)

 If true a sharable environment is open or created if none exist.
@item  wordlist_env_dir <directory> (default .)

 Only valid if
@code{wordlist_env_share
} set to
@code{true.
}
Specify the directory in which the sharable environment will 
be created. All
inverted indexes specified with a non-absolute pathname will be
created relative to this directory.
@end table


@node WordRecordInfo
@section WordRecordInfo


@menu
* WordRecordInfo NAME::         
* WordRecordInfo SYNOPSIS::     
* WordRecordInfo DESCRIPTION::  
* WordRecordInfo CONFIGURATION::  
@end menu

@node WordRecordInfo NAME
@subsection WordRecordInfo NAME

information on the record structure of the inverted index.



@node WordRecordInfo SYNOPSIS
@subsection WordRecordInfo SYNOPSIS

@example

Only called thru WordContext::Initialize()
@end example


@node WordRecordInfo DESCRIPTION
@subsection WordRecordInfo DESCRIPTION


The structure of a record is very limited. It can contain
a single integer value or a string.



@node WordRecordInfo CONFIGURATION
@subsection WordRecordInfo CONFIGURATION

For more information on the configuration attributes and a complete list of attributes, see the mifluz(3) manual page.
@table @samp
@item  wordlist_wordrecord_description @{NONE|DATA|STR@} (no default)

 NONE: the record is empty


DATA: the record contains an integer (unsigned int)


STR: the record contains a string (String)
@end table


@node WordRecord
@section WordRecord


@menu
* WordRecord NAME::             
* WordRecord SYNOPSIS::         
* WordRecord DESCRIPTION::      
* WordRecord ASCII FORMAT::     
* WordRecord METHODS::          
@end menu

@node WordRecord NAME
@subsection WordRecord NAME

inverted index record.



@node WordRecord SYNOPSIS
@subsection WordRecord SYNOPSIS

@example

#include <WordRecord.h>

WordContext* context;
WordRecord* record = context->Record();
if(record->DefaultType() == WORD_RECORD_DATA) @{
  record->info.data = 120;
@} else if(record->DefaultType() == WORD_RECORD_STR) @{
  record->info.str = "foobar";
@}
delete record;
@end example


@node WordRecord DESCRIPTION
@subsection WordRecord DESCRIPTION


The record can contain an integer, if the default record
type (see CONFIGURATION in
@code{WordKeyInfo
}) is set to
@code{DATA
}
or a string if set to
@code{STR.
}
If the type is set to
@code{NONE
} the record does not contain
any usable information.

Although constructors may be used, the prefered way to create a 
WordRecord object is by using the
@strong{WordContext::Record
} method.



@node WordRecord ASCII FORMAT
@subsection WordRecord ASCII FORMAT


If default type is
@code{DATA
} it is the decimal representation of
an integer. If default type is
@code{NONE
} it is the empty string.



@node WordRecord METHODS
@subsection WordRecord METHODS

@table @samp
@item   inline WordRecord(WordContext* ncontext) 
Constructor. Build an empty record.
The
@strong{ncontext
} argument must be a pointer to a valid
WordContext object.
@item   inline void Clear() 
Reset to empty and set the type to the default specified
in the configuration.
@item   inline int DefaultType() 
Return the default type WORD_RECORD_@{DATA,STR,NONE@}
@item   inline int Pack(String& packed) const 
Convert the object to a representation for disk storage written
in the
@strong{packed
} string.
Return OK on success, NOTOK otherwise.
@item   inline int Unpack(const char* string, int length) 

Alias for Unpack(String(string, length))
@item   inline int Unpack(const String& packed) 
Read the object from a representation for disk storage contained
in the
@strong{packed
} argument.
Return OK on success, NOTOK otherwise.
@item   int Set(const String& bufferin)
Set the whole structure from ASCII string description stored
in the
@strong{bufferin
} argument.
Return OK on success, NOTOK otherwise.
@item   int Get(String& bufferout) const
Convert the whole structure to an ASCII string description
and return it in the
@strong{bufferout
} argument.
Return OK on success, NOTOK otherwise.
@item   String Get() const
Convert the whole structure to an ASCII string description
and return it.
@item   inline WordContext* GetContext() 
Return a pointer to the WordContext object used to create
this instance.
@item   inline const WordContext* GetContext() const 
Return a pointer to the WordContext object used to create
this instance as a const.
@item   int Write(FILE* f) const
Print object in ASCII form on descriptor
@strong{f
} using the
Get method.
@end table


@node WordReference
@section WordReference


@menu
* WordReference NAME::          
* WordReference SYNOPSIS::      
* WordReference DESCRIPTION::   
* WordReference ASCII FORMAT::  
* WordReference METHODS::       
@end menu

@node WordReference NAME
@subsection WordReference NAME

inverted index occurrence.



@node WordReference SYNOPSIS
@subsection WordReference SYNOPSIS

@example

#include <WordReference.h>

WordContext* context;
WordReference* word = context->Word("word");
WordReference* word = context->Word();
WordReference* word = context->Word(WordKey("key 1 2"), WordRecord());

WordKey key = word->Key()
WordKey record = word->Record()

word->Clear();

delete word;
@end example


@node WordReference DESCRIPTION
@subsection WordReference DESCRIPTION


A
@code{WordReference
} object is an agregate of a
@code{WordKey
} object
and a
@code{WordRecord
} object.

Although constructors may be used, the prefered way to create a 
WordReference object is by using the
@strong{WordContext::Word
} method.



@node WordReference ASCII FORMAT
@subsection WordReference ASCII FORMAT


The ASCII description is a string with fields separated by tabs or
white space. It is made of the ASCII description of a
@code{WordKey
} object immediately followed by the ASCII
description of a
@code{WordRecord
} object.  See the corresponding
manual pages for more information.



@node WordReference METHODS
@subsection WordReference METHODS

@table @samp
@item   WordReference(WordContext* ncontext) :
Constructor. Build an object with empty key and empty record.
The
@strong{ncontext
} argument must be a pointer to a valid
WordContext object.
@item   WordReference(WordContext* ncontext, const String& key0, const String& record0) :
Constructor. Build an object from disk representation of
@strong{key
}
and
@strong{record
}.
The
@strong{ncontext
} argument must be a pointer to a valid
WordContext object.
@item   WordReference(WordContext* ncontext, const String& word) :
Constructor. Build an object with key word set to
@strong{word
}
and otherwise empty and empty record.
The
@strong{ncontext
} argument must be a pointer to a valid
WordContext object.
@item   void Clear() 
Reset to empty key and record
@item   inline WordContext* GetContext() 
Return a pointer to the WordContext object used to create
this instance.
@item   inline const WordContext* GetContext() const 
Return a pointer to the WordContext object used to create
this instance as a const.
@item   inline String& GetWord() 
Return the
@strong{word
} data member.
@item   inline const String& GetWord() const 
Return the
@strong{word
} data member as a const.
@item   inline void SetWord(const String& nword) 
Set the
@strong{word
} data member from the
@strong{nword
} argument.
@item   WordKey& Key() 
Return the key object.
@item   const WordKey& Key() const 
Return the key object as const.
@item   WordRecord& Record() 
Return the record object.
@item   const WordRecord& Record() const 
Return the record object as const.
@item   void Key(const WordKey& arg) 
Copy
@strong{arg
} in the key part of the object.
@item   int KeyUnpack(const String& packed) 
Set key structure from disk storage format as found in
@strong{packed
} string.
Return OK if successfull, NOTOK otherwise.
@item   String KeyPack() const 
Convert key object into disk storage format as found in 
return the resulting string.
@item   int KeyPack(String& packed) const 
Convert key object into disk storage format as found in 
and place the result in
@strong{packed
} string.
Return OK if successfull, NOTOK otherwise.
@item   void Record(const WordRecord& arg) 
Copy
@strong{arg
} in the record part of the object.
@item   int RecordUnpack(const String& packed) 
Set record structure from disk storage format as found in
@strong{packed
} string.
Return OK if successfull, NOTOK otherwise.
@item   String RecordPack() const 
Convert record object into disk storage format as found in 
return the resulting string.
@item   int RecordPack(String& packed) const 
Convert record object into disk storage format as found in 
and place the result in
@strong{packed
} string.
Return OK if successfull, NOTOK otherwise.
@item   inline int Pack(String& ckey, String& crecord) const 
Short hand for KeyPack(
@strong{ckey
}) RecordPack(
@strong{crecord
}).
@item   int Unpack(const String& ckey, const String& crecord) 
Short hand for KeyUnpack(
@strong{ckey
}) RecordUnpack(
@strong{crecord
}).
@item   int Merge(const WordReference& other)
Merge key with other.Key() using the
@code{WordKey::Merge
} method:
key.Merge(other.Key()).
See the corresponding manual page for details. Copy other.record
into the record part of the object.
@item   static WordReference Merge(const WordReference& master, const WordReference& slave) 
Copy
@strong{master
} before merging with
@strong{master.
}Merge(
@strong{slave
})
and return the copy. Prevents alteration of
@strong{master
}.
@item   int Set(const String& bufferin)
Set the whole structure from ASCII string in
@strong{bufferin
}.
See
@code{ASCII FORMAT
} section.
Return OK if successfull, NOTOK otherwise.
@item   int Get(String& bufferout) const
Convert the whole structure to an ASCII string description 
in
@strong{bufferout.
}
See
@code{ASCII FORMAT
} section.
Return OK if successfull, NOTOK otherwise.
@item   String Get() const
Convert the whole structure to an ASCII string description 
and return it.
See
@code{ASCII FORMAT
} section.
@item   int Write(FILE* f) const
Print object in ASCII form on
@strong{f
} (uses
@code{Get
} method).
See
@code{ASCII FORMAT
} section.
@item   void Print() const
Print object in ASCII form on
@strong{stdout
} (uses
@code{Get
} method).
See
@code{ASCII FORMAT
} section.
@end table


@node WordCursor
@section WordCursor


@menu
* WordCursor NAME::             
* WordCursor SYNOPSIS::         
* WordCursor DESCRIPTION::      
* WordCursor METHODS::          
@end menu

@node WordCursor NAME
@subsection WordCursor NAME


abstract class to search and retrieve entries in a WordList object.



@node WordCursor SYNOPSIS
@subsection WordCursor SYNOPSIS

@example

#include <WordList.h>

int callback(WordList *, WordDBCursor& , const WordReference *, Object &)
@{
   ...
@}

Object* data = ...

WordList *words = ...;

WordCursor *search = words->Cursor(WordKey("word <UNDEF> <UNDEF>"), HTDIG_WORDLIST_COLLECTOR);

if(search->Walk() == NOTOK) bark;
List* results = search->GetResults();

WordCursor *search = words->Cursor(callback, data);
WordCursor *search = words->Cursor(WordKey("word <UNDEF> <UNDEF>"));
WordCursor *search = words->Cursor(WordKey("word <UNDEF> <UNDEF>"), callback, data);
WordCursor *search = words->Cursor(WordKey());

search->WalkInit();
if(search->WalkNext() == OK)
  dosomething(search->GetFound());
search->WalkFinish();
@end example


@node WordCursor DESCRIPTION
@subsection WordCursor DESCRIPTION


WordCursor is an iterator on an inverted index. It is created by
asking a
@code{WordList
} object with the
@code{Cursor.
} There is
no other way to create a WordCursor object.
When the
@code{Walk*
} methods return,
the WordCursor object contains the result of the search and 
status information that indicates if it reached the end of 
the list (IsAtEnd() method).

The
@strong{callback
} function that is called each time a match is
found takes the following arguments:
@example
WordList* words pointer to the inverted index handle.
WordDBCursor& cursor to call Del() and delete the current match
WordReference* wordRef is the match
Object& data is the user data provided by the caller when
             search began.
@end example

The
@code{WordKey
} object that specifies the search criterion
may be used as follows (assuming word is followed by DOCID and
LOCATION):

Ex1:
@strong{WordKey()
} walk the entire list of occurences.

Ex2:
@strong{WordKey("word <UNDEF> <UNDEF>")
} find all occurrences
of
@code{word
}.

Ex3:
@strong{WordKey("meet <UNDEF> 1")
} find all occurrences of
@code{meet
} that occur at LOCATION 1 in any DOCID. This can
be inefficient since the search has to scan all occurrences
of
@code{meet
} to find the ones that occur at LOCATION 1.

Ex4:
@strong{WordKey("meet 2 <UNDEF>")
} find all occurrences of
@code{meet
} that occur in DOCID 2, at any location.

WordList is an abstract class and cannot be instanciated. 
See the WordCursorOne manual page for an actual implementation of
a WordCursor object.



@node WordCursor METHODS
@subsection WordCursor METHODS

@table @samp
@item   virtual void Clear() = 0
Clear all data in object, set
@strong{GetResult()
} data to NULL but
do not delete it (the application is responsible for that).
@item   virtual inline int IsA() const 
Returns the type of the object. May be overloaded by
derived classes to differentiate them at runtime.
Returns WORD_CURSOR.
@item   virtual inline int Optimize() 
Optimize the cursor before starting a Walk.
Returns OK on success, NOTOK otherwise.
@item   virtual int ContextSave(String& buffer) const = 0
Save in
@strong{buffer
} all the information necessary to resume
the walk at the point it left. The ASCII representation of the
last key found (GetFound()) is written in
@strong{buffer
} using the
WordKey::Get method.
@item   virtual int ContextRestore(const String& buffer) = 0
Restore from buffer all the information necessary to 
resume the walk at the point it left. The
@strong{buffer
} is expected
to contain an ASCII representation of a WordKey (see WordKey::Set
method). A
@strong{Seek
} is done on the key and the object is prepared
to jump to the next occurrence when
@strong{WalkNext
} is called (the
cursor_get_flags is set to
@code{DB_NEXT.
}
@item   virtual int Walk() = 0
Walk and collect data from the index. 
Returns OK on success, NOTOK otherwise.
@item   virtual int WalkInit() = 0
Must be called before other Walk methods are used.
Fill internal state according to input parameters 
and move before the first matching entry.
Returns OK on success, NOTOK otherwise.
@item   virtual int WalkRewind() = 0
Move before the first index matching entry.
Returns OK on success, NOTOK otherwise.
@item   virtual int WalkNext() = 0
Move to the next matching entry.  At end of list, WORD_WALK_ATEND
is returned.  Returns OK on success, NOTOK otherwise. When OK
is returned, the GetFound() method returns the matched entry.
When WORD_WALK_ATEND is returned, the GetFound() method returns
an empty object if the end of the index was reached or the match
that was found and that is greated than the specified search
criterion.
@item   virtual int WalkNextStep() = 0
Advance the cursor one step. The entry pointed to by the cursor may
or may not match the requirements.  Returns OK if entry pointed
by cursor matches requirements.  Returns NOTOK on
failure. Returns WORD_WALK_NOMATCH_FAILED if the current entry
does not match requirements, it's safe to call WalkNextStep again
until either OK or NOTOK is returned.
@item   virtual int WalkNextExclude(const WordKey& key) 
Return 0 if this key must not be returned by WalkNext as a valid
match. The WalkNextStep method calls this virtual method immediately
after jumping to the next entry in the database. This may be used,
for instance, to skip entries that were selected by a previous 
search.
@item   virtual int WalkFinish() = 0
Terminate Walk, free allocated resources.
Returns OK on success, NOTOK otherwise.
@item   virtual int Seek(const WordKey& patch) = 0
Move before the inverted index position specified in
@strong{patch.
}
May only be called after a successfull call to the
@code{WalkNext
}
or
@code{WalkNextStep
}method.
Copy defined fields from
@strong{patch
} into a copy of the
@code{found
} data member and 
initialize internal state so that
@code{WalkNext
} jumps to
this key next time it's called (cursor_get_flag set to DB_SET_RANGE).
Returns OK if successfull, NOTOK otherwise.
@item   virtual inline int IsAtEnd() const 
Returns true if cursor is positioned after the last possible
match, false otherwise.
@item   virtual inline int IsNoMatch() const 
Returns true if cursor hit a value that does not match search criterion.
@item   inline WordKey& GetSearch() 
Returns the search criterion.
@item   inline int GetAction() const 
Returns the type of action when a matching entry
is found.
@item   inline List *GetResults() 
Returns the list of WordReference found. The application
is responsible for deallocation of the list. If the
@strong{action
}
input flag bit HTDIG_WORDLIST_COLLECTOR is not set, return a NULL
pointer.
@item   inline List *GetTraces() 
For debugging purposes. Returns the list of WordReference hit 
during the search
process. Some of them match the searched key, some don't.
The application is responsible for deallocation of the list.
@item   inline void SetTraces(List* traceRes_arg) 
For debugging purposes. Set the list of WordReference hit
during the search process.
@item   inline const WordReference& GetFound() 
Returns the last entry hit by the search. Only contains
a valid value if the last
@code{WalkNext
} or
@code{WalkNextStep
}
call was successfull (i.e. returned OK).
@item   inline int GetStatus() const 
Returns the status of the cursor which may be 
OK or WORD_WALK_ATEND.
@item   virtual int Get(String& bufferout) const = 0
Convert the whole structure to an ASCII string description.
Returns OK if successfull, NOTOK otherwise.
@item   inline String Get() const 
Convert the whole structure to an ASCII string description
and return it.
@item   virtual int Initialize(WordList *nwords, const WordKey &nsearchKey, wordlist_walk_callback_t ncallback, Object * ncallback_data, int naction) = 0
Protected method. Derived classes should use this function to initialize
the object if they do not call a WordCursor constructor in their own
constructutor. Initialization may occur after the object is created
and must occur before a
@strong{Walk*
} method is called. See the 
DESCRIPTION section for the semantics of the arguments.
Return OK on success, NOTOK on error.
@item   WordKey searchKey
Input data. The key to be searched, see DESCRIPTION for more information.
@item   WordReference found
Output data. Last match found. Use GetFound() to retrieve it.
@item   int status
Output data. WORD_WALK_ATEND if cursor is past last match, 
OK otherwise. Use GetStatus() to retrieve it.
@item   WordList *words
The inverted index used by this cursor.
@end table


@node WordCursorOne
@section WordCursorOne


@menu
* WordCursorOne NAME::          
* WordCursorOne SYNOPSIS::      
* WordCursorOne DESCRIPTION::   
* WordCursorOne METHODS::       
@end menu

@node WordCursorOne NAME
@subsection WordCursorOne NAME


search and retrieve entries in a WordListOne object.



@node WordCursorOne SYNOPSIS
@subsection WordCursorOne SYNOPSIS

@example

#include <WordList.h>

int callback(WordList *, WordDBCursor& , const WordReference *, Object &)
@{
   ...
@}

Object* data = ...

WordList *words = ...;

WordCursor *search = words->Cursor(callback, data);
WordCursor *search = words->Cursor(WordKey("word <UNDEF> <UNDEF>"));
WordCursor *search = words->Cursor(WordKey("word <UNDEF> <UNDEF>"), callback, data);
WordCursor *search = words->Cursor(WordKey());

...

if(search->Walk() == NOTOK) bark;
List* results = search->GetResults();

search->WalkInit();
if(search->WalkNext() == OK)
  dosomething(search->GetFound());
search->WalkFinish();
@end example


@node WordCursorOne DESCRIPTION
@subsection WordCursorOne DESCRIPTION


WordCursorOne is a WordCursor derived class that implements search
in a WordListOne object. It currently is the only derived class of
the WordCursor object. Most of its behaviour is described in the
WordCursor manual page, only the behaviour specific to WordCursorOne
is documented here.




@node WordCursorOne METHODS
@subsection WordCursorOne METHODS

@table @samp
@item   WordCursorOne(WordList *words)
Private constructor. Creator of the object must then call Initialize()
prior to using any other methods.
@item   WordCursorOne(WordList *words, wordlist_walk_callback_t callback, Object * callback_data)
Private constructor. See WordList::Cursor method with same prototype for
description.
@item   WordCursorOne(WordList *words, const WordKey &searchKey, int action = HTDIG_WORDLIST_WALKER)
Private constructor. See WordList::Cursor method with same prototype for
description.
@item   WordCursorOne(WordList *words, const WordKey &searchKey, wordlist_walk_callback_t callback, Object * callback_data)
Private constructor. See WordList::Cursor method with same prototype for
description.
@end table


@node WordMonitor
@section WordMonitor


@menu
* WordMonitor NAME::            
* WordMonitor SYNOPSIS::        
* WordMonitor DESCRIPTION::     
* WordMonitor CONFIGURATION::   
@end menu

@node WordMonitor NAME
@subsection WordMonitor NAME

monitoring classes activity.



@node WordMonitor SYNOPSIS
@subsection WordMonitor SYNOPSIS

@example

Only called thru WordContext::Initialize()
@end example


@node WordMonitor DESCRIPTION
@subsection WordMonitor DESCRIPTION


The test directory contains a
@code{benchmark-report
} script used to generate
and archive graphs from the output of
@code{WordMonitor
}.



@node WordMonitor CONFIGURATION
@subsection WordMonitor CONFIGURATION

For more information on the configuration attributes and a complete list of attributes, see the mifluz(3) manual page.
@table @samp
@item  wordlist_monitor_period <sec> (default 0)

 If the value
@strong{sec
} is a positive integer, set a timer to
print reports every
@strong{sec
} seconds. The timer is set using
the ALRM signal and will fail if the calling application already
has a handler on that signal.
@item  wordlist_monitor_output <file>[,@{rrd,readable] (default stderr)

 Print reports on
@strong{file
} instead of the default
@strong{stderr
}.
If
@strong{type
} is set to
@strong{rrd
} the output is fit for the
@code{benchmark-report
} script. Otherwise it a (hardly :-) readable
string.
@end table


@node Configuration
@section Configuration


@menu
* Configuration NAME::          
* Configuration SYNOPSIS::      
* Configuration DESCRIPTION::   
* Configuration FILE FORMAT::   
* Configuration METHODS::       
@end menu

@node Configuration NAME
@subsection Configuration NAME


reads the configuration file and manages it in memory.



@node Configuration SYNOPSIS
@subsection Configuration SYNOPSIS

@example

#include <Configuration.h>

Configuration config;

ConfigDefault config_defaults = @{
  @{ "verbose", "true" @},
  @{ 0, 0 @}
@};

config.Defaults(config_defaults);

config.Read("/spare2/myconfig") ;

config.Add("sync", "false");

if(config["sync"]) ...
if(config.Value("rate") < 50) ...
if(config.Boolean("sync")) ...
@end example


@node Configuration DESCRIPTION
@subsection Configuration DESCRIPTION


The primary purpose of the
@strong{Configuration
} class is to parse
a configuration file and allow the application to modify the internal
data structure produced. All values are strings and are converted by the 
appropriate accessors. For instance the
@strong{Boolean
} method will 
return numerical true (not zero) if the string either contains 
a number that is different from zero or the string
@code{true
}.

The
@code{ConfigDefaults
} type is a structure of two char pointers:
the name of the configuration attribute and it's value. The end of
the array is the first entry that contains a null pointer instead of
the attribute name. Numerical
values must be in strings. For instance:
@example
ConfigDefault* config_defaults = @{
  @{ "wordlist_compress", "true" @},
  @{ "wordlist_page_size", "8192" @},
  @{ 0, 0 @}
@};
@end example
The additional
fields of the
@strong{ConfigDefault
} are purely informative. 



@node Configuration FILE FORMAT
@subsection Configuration FILE FORMAT


The configuration file is a plain ASCII text file. Each line in
the file is either a comment or an attribute.
Comment lines are blank lines or lines that start with a '#'.
Attributes consist of a variable name and an associated
value:
@example
<name>:<whitespace><value><newline>
@end example

The <name> contains any alphanumeric character or
underline (_) The <value> can include any character
except newline. It also cannot start with spaces or tabs since
those are considered part of the whitespace after the colon. It
is important to keep in mind that any trailing spaces or tabs
will be included.

It is possible to split the <value> across several
lines of the configuration file by ending each line with a
backslash (\). The effect on the value is that a space is
added where the line split occurs.

A configuration file can include another file, by using the special
<name>,
@code{include
}. The <value> is taken as
the file name of another configuration file to be read in at
this point. If the given file name is not fully qualified, it is
taken relative to the directory in which the current configuration
file is found. Variable expansion is permitted in the file name.
Multiple include statements, and nested includes are also permitted.
@example
include: common.conf
@end example




@node Configuration METHODS
@subsection Configuration METHODS

@table @samp
@item   Configuration()
Constructor
@item   ~Configuration() 
Destructor
@item   void Add(const String& str)
Add configuration item
@strong{str
} to the configuration. The value
associated with it is undefined.
@item   void Add(const String& name, const String& value)
Add configuration item
@strong{name
} to the configuration and associate
it with
@strong{value
}.
@item   int Remove(const String& name)
Remove the
@strong{name
} from the configuration.
@item   void NameValueSeparators(const String& s)
Let the Configuration know how to parse name value pairs.
Each character of string
@strong{s
} is a valid separator between
the
@code{name
} and the
@code{value.
}
@item   virtual int Read(const String& filename)
Read name/value configuration pairs from the file
@strong{filename
}.
@item   const String Find(const String& name) const
Return the value of configuration attribute
@strong{name
} as a
@code{String
}.
@item   const String operator[](const String& name) const
Alias to the
@strong{Find
} method.
@item   int Value(const String& name, int default_value = 0) const
Return the value associated with the configuration attribute
@strong{name
}, converted to integer using the atoi(3) function.
If the attribute is not found in the configuration and 
a
@strong{default_value
} is provided, return it.
@item   double Double(const String& name, double default_value = 0) const
Return the value associated with the configuration attribute
@strong{name
}, converted to double using the atof(3) function.
If the attribute is not found in the configuration and 
a
@strong{default_value
} is provided, return it.
@item   int Boolean(const String& name, int default_value = 0) const
Return 1 if the value associated to
@strong{name
} is 
either
@strong{1, yes
} or
@strong{true
}.
Return 0 if the value associated to
@strong{name
} is 
either
@strong{0, no
} or
@strong{false
}.
@item   void Defaults(const ConfigDefaults *array)
Load configuration attributes from the
@code{name
} and
@code{value
}
members of the
@strong{array
} argument.
@end table


@node mifluz
@section mifluz


@menu
* mifluz NAME::                 
* mifluz SYNOPSIS::             
* mifluz DESCRIPTION::          
* mifluz CLASSES AND COMMANDS::  
* mifluz CONFIGURATION::        
* mifluz ENVIRONMENT::          
@end menu

@node mifluz NAME
@subsection mifluz NAME

C++ library to use and manage inverted indexes



@node mifluz SYNOPSIS
@subsection mifluz SYNOPSIS

@example
#include <mifluz.h>

main()
@{
   Configuration* config = WordContext::Initialize();

   WordList* words = new WordList(*config);

   ...

   delete words;

   WordContext::Finish();
@}
@end example


@node mifluz DESCRIPTION
@subsection mifluz DESCRIPTION


The purpose of
@code{mifluz
} is to provide a C++ library to build and query a
full text inverted index. It is dynamically updatable, scalable (up to
1Tb indexes), uses a controlled amount of memory, shares index files
and memory cache among processes or threads and compresses index files
to 50% of the raw data. The structure of the index is configurable at
runtime and allows inclusion of relevance ranking information. The
query functions do not require loading all the occurrences of a
searched term.  They consume very few resources and many searches can
be run in parallel.

The file management library used in mifluz is a modified Berkeley DB 
(www.sleepycat.com) version 3.1.14.



@node mifluz CLASSES AND COMMANDS
@subsection mifluz CLASSES AND COMMANDS

@table @samp
@item  Configuration

 
reads the configuration file and manages it in memory.
@item  WordContext

 
read configuration and setup mifluz context.
@item  WordCursor

 
abstract class to search and retrieve entries in a WordList object.
@item  WordCursorOne

 
search and retrieve entries in a WordListOne object.
@item  WordDBInfo

 inverted index usage environment.
@item  WordDict

 
manage and use an inverted index dictionary.
@item  WordKey

 inverted index key.
@item  WordKeyInfo

 information on the key structure of the inverted index.
@item  WordList

 
abstract class to manage and use an inverted index file.
@item  WordListOne

 
manage and use an inverted index file.
@item  WordMonitor

 monitoring classes activity.
@item  WordRecord

 inverted index record.
@item  WordRecordInfo

 information on the record structure of the inverted index.
@item  WordReference

 inverted index occurrence.
@item  WordType

 defines a word in term of allowed characters, length etc.
@item  htdb_dump

 
dump the content of an inverted index in Berkeley DB fashion
@item  htdb_load

 
displays statistics for Berkeley DB environments.
@item  htdb_stat

 
displays statistics for Berkeley DB environments.
@item  mifluzdict

 
dump the dictionnary of an inverted index.
@item  mifluzdump

 
dump the content of an inverted index.
@item  mifluzload

 
load the content of an inverted index.
@item  mifluzsearch

 search the content of an inverted index.
@end table


@node mifluz CONFIGURATION
@subsection mifluz CONFIGURATION

The format of the configuration file read by WordContext::Initialize is:
@example
keyword: value
@end example
Comments may be added on lines starting with a #. The default
configuration file is read from from the file pointed by the
@strong{MIFLUZ_CONFIG
} environment variable or
@strong{~/.mifluz
} or
@strong{/etc/mifluz.conf
} in this
order. If no configuration file is available, builtin defaults are used.
Here is an example configuration file:
@example
wordlist_extend: true
wordlist_cache_size: 10485760
wordlist_page_size: 32768
wordlist_compress: 1
wordlist_wordrecord_description: NONE
wordlist_wordkey_description: Word/DocID 32/Flags 8/Location 16
wordlist_monitor: true
wordlist_monitor_period: 30
wordlist_monitor_output: monitor.out,rrd
@end example
@table @samp
@item  wordlist_allow_numbers @{true|false@} <number> (default false)

 A digit is considered a valid character within a word if
this configuration parameter is set to
@code{true
} otherwise
it is an error to insert a word containing digits.
See the
@strong{Normalize
} method for more information.
@item  wordlist_cache_inserts @{true|false@} (default false)

 If true all
@strong{Insert
} calls are cached in memory. When the 
WordList object is closed or a different access method is called
the cached entries are flushed in the inverted index.
@item  wordlist_cache_max <bytes> (default 0)

 Maximum size of the cumulated cache files generated when doing bulk
insertion with the
@strong{BatchStart()
} function. When this limit is
reached, the cache files are all merged into the inverted index. 
The value 0 means infinite size allowed.
See WordList(3) for the rationale behind cache file handling.
@item  wordlist_cache_size <bytes> (default 500K)

 Berkeley DB cache size (see Berkeley DB documentation)
Cache makes a huge difference in performance. It must be at least 2%
of the expected total data size. Note that if compression is activated
the data size is eight times larger than the actual file size. In this
case the cache must be scaled to 2% of the data size, not 2% 
of the file size. See
@strong{Cache tuning
} in the mifluz guide for
more hints.
See WordList(3) for the rationale behind cache file handling.
@item  wordlist_compress @{true|false@} (default false)

 Activate compression of the index. The resulting index is eight times
smaller than the uncompressed index.
@item  wordlist_env_dir <directory> (default .)

 Only valid if
@code{wordlist_env_share
} set to
@code{true.
}
Specify the directory in which the sharable environment will 
be created. All
inverted indexes specified with a non-absolute pathname will be
created relative to this directory.
@item  wordlist_env_share @{true,false@} (default false)

 If true a sharable environment is open or created if none exist.
@item  wordlist_env_skip @{true,false@} (default false)

 If true no environment is created at all. This must never 
be used if a
@code{WordList
} object is created. It may be
useful if only
@code{WordKey
} objects are used, for instance.
@item  wordlist_extend @{true|false@} (default false)

 If
@strong{true
} maintain reference count of unique 
words. The
@strong{Noccurrence
} method gives access to this count.
@item  wordlist_locale <locale> (default C)

 Set the locale of the program to
@strong{locale
}. See setlocale(3)
for more information.
@item  wordlist_lowercase @{true|false@} <number> (default true)

 If a word contains upper case letters it is converted to lowercase
if this configuration parameter is true, otherwise it is left
untouched.
@item  wordlist_maximum_word_length <number> (default 25)

 The maximum length of a word.
See the
@strong{Normalize
} method for more information.
@item  wordlist_mimimun_word_length <number> (default 3)

 The minimum length of a word.
See the
@strong{Normalize
} method for more information.
@item  wordlist_monitor @{true|false@} (default false)

 If true create a
@code{WordMonitor
} instance to gather statistics and 
build reports.
@item  wordlist_monitor_output <file>[,@{rrd,readable] (default stderr)

 Print reports on
@strong{file
} instead of the default
@strong{stderr
}.
If
@strong{type
} is set to
@strong{rrd
} the output is fit for the
@code{benchmark-report
} script. Otherwise it a (hardly :-) readable
string.
@item  wordlist_monitor_period <sec> (default 0)

 If the value
@strong{sec
} is a positive integer, set a timer to
print reports every
@strong{sec
} seconds. The timer is set using
the ALRM signal and will fail if the calling application already
has a handler on that signal.
@item  wordlist_page_size <bytes> (default 8192)

 Berkeley DB page size (see Berkeley DB documentation)
@item  wordlist_truncate @{true|false@} <number> (default true)

 If a word is too long according to
the
@code{wordlist_maximum_word_length
} it is truncated
if this configuration parameter is
@code{true
} otherwise it
is considered an invalid word.
@item  wordlist_valid_punctuation [characters] (default none)

 A list of punctuation characters that may appear in a word. 
These characters will be removed from the word before insertion
in the index.
@item  wordlist_verbose <number> (default 0)

 Set the verbosity level of the WordList class.


1 walk logic


2 walk logic details


3 walk logic lots of details
@item  wordlist_wordkey_description <desc> (no default)

 Describe the structure of the inverted index key.
In the following explanation of the
@code{<desc>
} format,
mandatory words are
in bold and values that must be replaced in italic.


@strong{Word
}
@code{bits/name bits
}[/...]


The
@code{name
} is an alphanumerical symbolic name for the key field.
The
@code{bits
} is the number of bits required to store this field.
Note that all values are stored in unsigned integers (unsigned int).
Example:
@example
Word 8/Document 16/Location 8
@end example
@item  wordlist_wordkey_document [field ...] (default none)

 A white space separated list of field numbers that define a document.
The field number list must not contain gaps. For instance 1 2 3 is 
valid but 1 3 4 is not valid.
This configuration parameter is not used by the mifluz library
but may be used by a query application to define the semantic of 
a document. In response to a query, the application will return a
list of results in which only distinct documents will be shown.
@item  wordlist_wordkey_location field (default none)

 A single field number that contains the position of a word in a
given document.
This configuration parameter is not used by the mifluz library
but may be used by a query application.
@item  wordlist_wordrecord_description @{NONE|DATA|STR@} (no default)

 NONE: the record is empty


DATA: the record contains an integer (unsigned int)


STR: the record contains a string (String)
@end table


@node mifluz ENVIRONMENT
@subsection mifluz ENVIRONMENT


@strong{MIFLUZ_CONFIG
} file name of configuration file read by
WordContext(3). Defaults to
@strong{~/.mifluz.
} or
@strong{/usr/etc/mifluz.conf
}


@node Concept Index
@unnumbered Index of Concepts

@printindex cp

@c @node Name Index
@c @unnumbered Index of File Names

@c @printindex fn

@summarycontents
@contents
@bye
